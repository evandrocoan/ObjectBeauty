

% Is it possible to keep my translation together with original text?
% https://tex.stackexchange.com/questions/5076/is-it-possible-to-keep-my-translation-together-with-original-text
\chapter{\lang{Theory base}{Fundamentação Teórica}}

Fazer depois que a fundamentação teórica estiver concluída.


\section{Compiladores e Tradutores}
\label{compiladoresEtradutores}

\lang{%
    This work aims to propose a translator \cite{generatingInterpretiveTranslators},
    where the input and output languages are the same language.
    Such translation objective is to change the language representational structure,
    but without affecting the language lex,
    syntactic or semantics, i.e.,
    the language meaning.

    This program class is commonly know as text formatters.
    The differential from this work from others is the goal of a single expandable tool,
    capable of manipulating all existent and future programming languages,
    based on the use of deterministic \cite{introductionToContextFreeGrammars}
    and controlled nondeterministic
    % \cite{TODO:section explaning what does controlled means}
    context free grammars.
}{%
    Em linguagens formais,
    tradutores são ferramentas que operam realizando a transformação de um programa de entrada,
    em um programa de saída \cite{generatingInterpretiveTranslators}.
    Diferente de um compilador,
    a linguagem de destino da ``tradução'' é do \textbf{mesmo nível} que a linguagem de origem.
    Por exemplo,
    dado um programa de entrada em C++ e
    um programa de saída em Java,
    tem~=se um processo de tradução (Figura \ref{fig:pictures/ProcessoTraducao.png}).
    \advisor{A tradução é diferente de um processo de compilação,
    que é dotado de mais etapas \cite{translatorGenerationCompilier}.
    }{Pelo outro lado,
    dado um programa de entrada em C++ e
    um programa de saída em \textit{Assembly},
    tem~=se um processo de compilação \cite{translatorGenerationCompilier}.
    }
    \begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{pictures/ProcessoTraducao.png}
    \caption[Processo de Tradução]{Processo de Tradução -- Fonte Própria,
    \citeonline{ahoCompilerDragonBook}}
    \label{fig:pictures/ProcessoTraducao.png}
    \end{figure}

    No processo de compilação ou
    tradução,
    um Analisador Léxico cria múltiplos \textit{tokens}.
    Um token é composto por diversos atributos como a posição e
    o \textit{lexema}, i.e.,
    a sequencia de caracteres que este token representa no programa de entrada.
    Uma vez que o programa é ``\textit{tokenizado}'' pelo Analisador Léxico,
    o Analisador Sintático constrói a Árvore Sintática do programa.

    Utilizando a Árvore Sintática do programa de entrada,
    o tradutor constrói uma nova Árvore Sintática correspondente a Árvore Sintática da linguagem do programa destino,
    utilizada para construir o código~=fonte do programa destino.
    Em um processo de compilação,
    não seria criado uma nova Árvore Sintática como no processo de tradução,
    mas sim a geração de código objeto ou
    binário \cite{ahoCompilerDragonBook}.

    Analisadores Sintáticos podem ser Ascendentes\footnote{
    Do inglês, \textit{Bottom~=Up}
    }
    ou Descendentes\footnote{
    Do inglês, \textit{Top~=Down}
    }.
    Devido a essa característica ambos possuem as suas vantagens e
    desvantagens.
    Um Analisador Ascendente realiza a construção da Árvore Sintática das folhas até a raíz,
    o contrário de um Analisador Descendente que realiza a construção da Árvore Sintática a partir da raíz até as folhas\footnote{
    Como pode ser observados em seus nomes,
    ambos os analisadores tanto da familia LL (Descendentes,
    \textit{Left-to-right, Leftmost derivation}) ou LR (Ascendentes, \textit{Left~=to~=right,
    Rightmost derivation}) fazem a leitura do programa de entrada da esquerda para a direita.
    }.

    Uma vantagem de um Analisador Ascendente é o suporte de uma maior classe de Gramáticas Determinísticas.
    Uma vantagem de um Analisador Descendente é a facilidade da recuperação de erros em relação aos Analisadores Ascendentes\footnote{
    Conceito abordado na
    \fullref{analisadoresSintaticos}
    }
    \cite{sippu1982,lr1ErrorRecovery,larkJosefGrosch}.


\section{Gramáticas}

    Gramáticas são conjuntos de regras que definem uma linguagem.
    Em linguagens formais,
    sendo $\alpha$ um não~=terminal,
    $\beta$ um terminal,
    $V_n$ um conjunto de não~=terminais,
    $V_t$ um conjunto de terminais e
    $V = V_n \cup V_t$,
    uma gramática é definida por quatro componentes:
    \begin{enumerate}%[nosep,nolistsep]
        \item \advisor{O}{Um} conjunto $V_t$ de símbolos terminais\advisor{ (também chamados
        de tokens ou símbolos do alfabeto da linguagem).
        Cada terminal corresponde a um símbolo presente na linguagem.
        }{,
        chamados algumas vezes de ``\textit{tokens}'' devido a sua forte conexão.
        Cada terminal corresponde a um símbolo presente no alfabeto da linguagem.
        }%
        Durante a Análise Léxica,
        os símbolos terminais serão utilizados definir os lexemas que são a base principal dos tokens.
        Na composição da Árvore Sintática,
        os ``\textit{tokens}'' ou terminais,
        serão sempre as folhas da Árvore Sintática.

        \item \advisor{O}{Um} conjunto $V_n$ de símbolos
        não~=terminais\advisor{ (algumas vezes chamados de ``variáveis sintáticas'').}{,
        algumas vezes chamados de ``variáveis sintáticas''.
        }
        não~=terminais servem para agrupar vários não~=terminais e\slash{}ou terminais.
        Na composição da Árvore Sintática,
        os símbolos não~=terminais sempre serão os nós da Árvore Sintática\footnote{
        Desde que a gramática da linguagem não contenha símbolos inúteis,
        i.e.,
        todos os símbolos da gramática são férteis e
        permitem a geração de palavras além do conjunto vazio $\varnothing$ \cite{hopcroftBook}
        }.
        Por convenção,
        e para evitar confusões entre quais são os símbolos terminais e não~=terminais,
        a intersecção entre o conjunto de símbolos terminais e
        não~=terminais é sempre vazia, i.e.,
        $V_n \cap V_t = \varnothing$.

        \item \label{definicaoDeGramatica}Um conjunto de produções $P$.
        Uma produção consiste em uma dupla elementos.
        O primeiro elemento é a cabeça ou
        lado esquerdo e
        representa a substituição ou
        consumo que será feito no programa de entrada.
        Ele é obrigatoriamente constituído de no mínimo um não~=terminal e
        um ou mais não~=terminais ou
        terminais.
        O segundo elemento é a cauda ou
        lado direito da produção,
        composto de terminais e\slash{}ou não~=terminais.
        Formalmente defini~=se uma produção pela seguinte regra,
        onde ``*'' representa o operador de fechamento do conjunto \cite{hopcroftBook}:
        $$P = \{\; \alpha ::= \beta \;|\; \alpha \in V^* V_n V^* \land \beta \in V^* \;\}$$

        \item Um símbolo inicial selecionado a partir do conjunto de símbolos não~=terminais.
        O símbolo inicial é utilizado para definir qual será a raíz da Árvore Sintática,
        e.g.,
        o última regra de produção utilizada para terminar o reconhecimento do programa de entrada em um Analisador Ascendente (ver seção \ref{reducoesEderivacoes}),
        e a primeira regra utilizada em um Analisador Descendente ou
        gerar~=se palavras desta linguagem\footnote{
        Processo natural quanto um Analisador Sintático realiza o reconhecimento de um programa de entrada.
        Para mais informações,
        veja a \fullref{reducoesEderivacoes}.
        }.
    \end{enumerate}


\subsection{Hierarquia de Chomsky}
\label{hierarquiaDeChomsky}

    Todas as gramáticas que existem são no mínimo\footnote{
    Caso contrário não serão gramáticas,
    mas qualquer outra definição no qual a Teoria de Linguagens Formais e
    Compiladores pode não se aplicar.
    }
    Gramáticas Tipo 0,
    também conhecidas como Gramáticas Irrestritas por que não possuem nenhuma restrição de complexidade de tempo,
    como os outros tipos de gramáticas a serem definidos nas próximas seções{}.
    A partir da adição restrições sobre a definição formal de gramática recém apresentada,
    também pode~=se \advisor{compreender}{realizar diversas classificações como} a hierarquia de \citeonline{chomskyGrammars1956},
    onde uma linguagem pode ser classificada como Regular,
    Livre de Contexto,
    Sensível ao Contexto e
    Irrestrita (Figura \ref{fig:pictures/HierarquiaDeChomsky.png}).
    \begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{pictures/HierarquiaDeChomsky.png}
    \begin{minipage}{\textwidth} \footnotesize
    *Para Gramáticas Regulares Determinísticas,
    complexidade linear ao tamanho da palavra de entrada para determinar se uma dada palavra pertence ou
    não a linguagem.
    Para Gramáticas Regulares Não~=Determinísticas,
    complexidade polinomial para construir as Árvores de Derivações e
    determinar se dada palavra pertence ou
    não a linguagem com algoritmos como CYK \cite{hopcroftBook,cykParsingAlgorithm}.
    Por fim,
    para Automatos Finitos Não~=Determinísticos ou
    Analisadores com Backtracking,
    tempo exponencial.

    **Para Gramáticas Livres de Contexto Determinísticas,
    também conhecidas como LR(K),
    complexidade linear ao tamanho da palavra de entrada (veja a seção \ref{gramaticasVersusLinguagens}).
    Para Gramáticas Livre de Contexto Não~=Determinísticas,
    vale o mesmo que para Linguagens Regulares Não~=Determinísticas logo acima,
    mas no lugar de Automatos Finitos,
    utilizam~=se Máquinas de Pilha.

    ***Para verificar se uma dada sentença pertence ou não a linguagem.
    \end{minipage}
    \caption[Hierarquia de Chomsky]{Hierarquia de Chomsky -- Fonte Própria\protect\footnotemark,
    \citeonline{sipserBook,ahoTheoryOfParsing,efficientNonDeterministicParsers,johnCocke}}
    \label{fig:pictures/HierarquiaDeChomsky.png}
    \end{figure}
    \footnotetext{
    Veja \citeonline{computationalComplexityAuroraBarak,complexityClasses} para aprender mais sobre Classes de Complexidade.
    }

    Toda Gramática Regular ou
    Livre de Contexto,
    é também uma Gramática Irrestrita ou
    Sensível ao Contexto,
    uma vez que Gramáticas Livres de Contexto ou
    Regulares são um subconjunto das Gramáticas Irrestritas ou
    Sensíveis ao Contexto como apresentado na Figura \ref{fig:pictures/HierarquiaDeChomsky.png}.
    Por isso,
    também pode~=se chamar uma dada Gramática Regular de Irrestrita ou
    Livre de Contexto.

    Quando diz~=se que existe Gramática Livre de Contexto para uma dada linguagem,
    pode~=se ter o equívoco de pensar que este é o melhor tipo,
    i.e.,
    o tipo mais eficiente em tempo computational de gramática no qual dada linguagem pode ser representada.
    Entretanto,
    precisa~=se tomar cuidado quando fala~=se sobre gramáticas e
    linguagens.

    Não pode~=se dizer que uma dada Linguagem é Livre de Contexto simplesmente por que existe uma Gramática Livre de Contexto para dada linguagem.
    Pois também é preciso que esta gramática seja o tipo mínimo no qual esta linguagem pode ser escrita.
    Sempre pode~=se escrever uma gramática menos eficiente do que o tipo mínimo de gramática que uma linguagem pode ser escrita.
    Para saber se este tipo de gramática é o mínimo,
    utiliza~=se o Lema do Bombeamento\footnote{
    Do inglês, \textit{Pumping Lemma} \cite{hopcroftBook,sipserBook}
    }
    para determinar e
    provar formalmente que dada gramática é o tipo mínimo de gramática para dada linguagem.


\subsection{Gramáticas Regulares}

    Gramáticas Regulares (também conhecidas como Tipo 3) são todas aquelas reconhecidas por Automatos Finitos Determinísticos e\slash{}ou Não~=Determinísticos.
    Gramáticas de Linguagens Regulares pela definição formal,
    são todas aquelas nos quais todas as Produções $P$ da gramática possuem a seguinte forma:
    $$ P = \{\; \alpha ::= a \beta \;|\; \alpha \in V_n \land a \in V_t
                \land \beta \in \{\; V_n \cup \varepsilon\; \} \;\} $$

\subsection{Gramáticas Livres de Contexto}

    Gramáticas Livres de Contexto (também conhecidas como Tipo 2) \cite{hopcroftBook} são todas aquelas reconhecidas por Automatos de Pilha Não~=Determinísticos.
    Gramáticas de Linguagens Livre de Contexto pela definição formal,
    são todas aquelas nos quais todas as Produções $P$ da gramática possuem a seguinte forma:
    $$ P = \{\; \alpha ::= \beta \;|\; \alpha \in V_n \land \beta \in V^* \;\} $$


\subsection{Gramáticas Sensíveis ao Contexto}

    Gramáticas Sensíveis ao Contexto (também conhecidas como Tipo 1) são todas aquelas reconhecidas por Automatos Linearmente Limitados,
    que tratam~=se somente de Máquinas de Turing \cite{sipserBook} com Fita (ou memória) Finita.
    Gramáticas de Linguagens Sensíveis ao Contexto pela definição formal,
    são todas aquelas nos quais todas as Produções $P$ da gramática possuem a seguinte forma:
    $$ P = \{\; \alpha ::= \beta \;|\; \alpha \in V^* V_n V^* \land \beta \in V^*
                \land \vert\alpha\vert \leq \vert\beta\vert \;\} $$


\subsection{Gramáticas Irrestritas}

    Por fim,
    as Gramáticas Irrestritas ou (também conhecidas como Tipo 0) possuem a mesma definição do
    que a definição válida de uma gramática como apresentado anteriormente (no
    \fullref{definicaoDeGramatica}).
    Gramáticas Irrestritas são reconhecidas somente por Máquinas de Turing\footnote{
    Máquinas de Turing possuem por definição fita (ou memória) ilimitada,
    mas não infinita,
    pois em um dado momento,
    somente uma quantidade finita de símbolos podem estar na fita,
    que continuamente pode crescer ilimitadamente.
    },
    e diferente das Gramáticas Sensíveis ao Contexto,
    a Máquina de Turing não possui parada garantida.

    Linguagens do Tipo 0 (ou Irrestritas) representam problemas incomputáveis e
    que podem ser representados de procedimentos \cite{sipserBook}.
    Já Linguagens do Tipo 1 (ou Sensíveis ao Contexto),
    representam todos os problemas computáveis e
    sua implementação pode ser representada por algoritmos,
    pois possuem parada garantida,
    apesar de terem em pior caso,
    tempo exponential ao contrário de tempo infinito como nas Linguagens Irrestritas.


\section{Analisadores Sintáticos}
\label{analisadoresSintaticos}

    Analisadores são equivalentes a Mecanismos Reconhecedores como Automatos Finitos,
    Automatos de Pilha ou
    Máquinas de Turing.
    No caso de outros Mecanismos como Automatos Finitos,
    o reconhecimento é feito a partir da especificação ou
    construção do automato que reconhece palavras de dada linguagem.
    Ambos gramáticas e
    automatos são equivalentes e
    existem algoritmos de conversão entre um e
    outro \cite{hopcroftBook}.

    Analisador Sintático\footnote{
    Além de Analisadores Sintáticos (Gramáticas Livre de Contexto),
    existem muitos outros como Analisadores Semânticos (Gramáticas Sensíveis ao Contexto) \cite{contextSensitiveParsing}.
    }
    é um nome dado para analisadores que recebem como entrada uma gramática que representa os aspectos estruturais de uma linguagem,
    i.e.,
    sua sintaxe \cite{ahoCompilerDragonBook}.
    Analisadores Sintáticos possuem muito mais utilidade do que somente checar se a sintaxe do programa de entrada está correta.
    Uma vez que eles também geram a Árvore Sintática do programa\footnote{
    Como visto no começo desde capítulo na \fullref{compiladoresEtradutores}.
    }
    que é utilizada para realizar a análise semântica e
    geração de código.


\subsection{Gramáticas $versus$ Linguagens}
\label{gramaticasVersusLinguagens}

    É importante fazer a distinção entre Gramáticas Livre de Contexto e
    as Linguagens Livre de Contexto.
    \citeonline{parikh1966} provou que existem linguagens nas quais não existem Gramáticas Não~=Ambíguas que representem estas linguagens.
    Tais linguagens são conhecidas como Linguagens Inerentemente Ambíguas\footnote{
    Do inglês,
    \textit{Inherently Ambiguous Languages}.
    }
    onde não existem Gramáticas Livre de Contexto Determinísticas capazes de representa~=las e
    tais Linguagens somente podem ser reconhecidas por Analisadores com Backtracking \cite{ahoCompilerDragonBook} ou
    Automatos de Pilha Não~=Determinísticos.

    A maior classe de Gramáticas Determinísticas suportadas por Analisadores Sintáticos são as Gramáticas LR(K)\footnote{
    Do inglês, \textit{Left~=to~=right,
    Rightmost derivation} em reverso com K símbolos de \textit{lookahead}.
    \textit{Rightmost} significa que ao realizar as derivações,
    escolhe~=se sempre o não~=terminal mais a direita.
    }.
    Analisadores LR(K) \cite{ahoCompilerDragonBook} são Ascendentes e
    reconhecem um subconjunto das Linguagens Livre de Contexto (Figura \ref{fig:pictures/LinguagensDeterministicas.png}).
    Já os Analisadores LL(K)\footnote{
    Do inglês, \textit{Left-to-right,
    Leftmost derivation} com K símbolos de \textit{lookahead}.
    \textit{Leftmost} significa que ao realizar as derivações,
    escolhe~=se sempre o não~=terminal mais a esquerda.
    }
    são Descendentes \cite{antlrBookTerrentParr,llStarAntlr} e
    reconhecem somente um subconjunto das Linguagens LR(K)\footnote{
    Diz~=se que uma linguagem é LR(K) ou
    LL(K) quando ela é reconhecida por este analisador
    }.

    A Figura \ref{fig:pictures/LinguagensDeterministicas.png} não é inteiramente um Diagrama de Venn \cite{generalizedVennDiagrams},
    inicialmente,
    nas camadas mais externas,
    ele é uma relação abstrata entre Linguagens Ambíguas e
    Gramáticas Determinísticas.
    O Conjunto das Gramáticas Livre de Contexto Determinísticas está contido dentro das Linguagens Livre de Contexto\footnote{
    Também existem Gramáticas Sensíveis ao Contexto Determinísticas \cite{contextSensitiveParsing},
    entretanto,
    algoritmos de análise possuem em pior caso,
    complexidade exponencial.
    }.
    O primeiro nível significa que todas as Linguagens Inerentemente Ambíguas\footnote{
    É comum confundir~=se e
    chamar Gramáticas de Inerentemente Ambíguas,
    mas esse termo não existe para gramáticas.
    Ou elas são Ambíguas ou
    Não.
    Somente uma linguagem pode ser Inerentemente Ambígua.
    }
    são representáveis somente por Gramáticas Ambíguas.

    O segundo nível significa que Linguagens Não~=Inerentemente Ambíguas\footnote{
    Somente utilizado para enfatizar o conjunto de Linguagens no qual existem Gramáticas Ambíguas e
    Determinísticas (ou Não~=Ambíguas).
    }
    podem ser representadas por Gramáticas Ambíguas e\slash{}ou Determinísticas.
    No terceiro nível encontra~=se as gramáticas que são mais importantes,
    as Gramáticas Determinísticas\footnote{
    As Gramáticas Determinísticas representam o conjunto de Linguagens que podem ser Analisadas Deterministicamente e
    tais Linguagens também podem ser conhecidas como LR(K),
    LR(K).
    Reveja os parágrafos após a Figura \ref{fig:pictures/HierarquiaDeChomsky.png}
    },
    que podem ser classificadas como LR(K),
    LL(K)\advisor{etc, }{ entre outros, }i.e.,
    de acordo com o tipo de analisador que pode ser construído.
    \begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{pictures/LinguagensDeterministicas.png}
    \caption[Gramáticas Determinísticas \textit{versus} suas Linguagens]{Gramáticas Determinísticas \textit{versus} suas Linguagens -- Fonte Própria,
    \citeonline{llVersusLrContainment,llContainmentInLalr,beatty1982,ahoCompilerDragonBook}}
    \label{fig:pictures/LinguagensDeterministicas.png}
    \end{figure}

    Diz~= que um Analisador Determinístico para dada gramática pode ser construído quando a criação de sua Tabela de Análise\footnote{
    Do inglês, \textit{Parsing Table}
    }
    \cite{ahoCompilerDragonBook} acontece sem conflitos.
    É importante notar que usualmente o processo de análise por um analisador,
    seja ele LR(K) ou
    LL(K),
    acontece em duas etapas.
    Com a exceção dos Analisadores LL(K) que também podem ser facilmente construídos programaticamente,
    i.e.,
    com o programador construindo manualmente como deve acontecer cada transição de estado do analisador \cite{ahoCompilerDragonBook}.

    Na primeira etapa do analisador utilizam~=se algoritmos de construção da Tabela de Análise.
    Quando a tabela está construída sem conflitos (este analisador portanto,
    é determinístico),
    entra em cena o algoritmo de análise na segunda etapa,
    que utilizando a Tabela de Análise,
    realiza o reconhecimento do programa de entrada.

    Como única diferença entre os Analisadores LR(K),
    LALR(K) e
    SLR(K) é exatamente construção da Tabela de Análise,
    ambos possuem a mesma complexidade de análise linear \cite{knuthLrParser1965} ao tamanho do programa\footnote{
    Quando refere~=se a programa,
    fala~=se da \textit{string} ou
    texto que será analisado e
    decidir se tal programa é um programa da linguagem que se está analisando.
    Um ponto curioso,
    caso o programa não seja aceito pelo analisador,
    ele não é um programa com erros,
    mas um programa inválido,
    i.e.,
    de uma outra linguagem,
    que não é a linguagem que está sendo analisada.
    Comumente ou
    informalmente,
    chamamos estes programas como programas com erros (de sintaxe).
    }
    de entrada que será analisado \cite{linearLL1AndLR1Grammars,generalContextFreeParsingAlgorithm}.

    No caso de conflitos na Tabela de Análise,
    a gramática não pode ser analisada deterministicamente e
    algoritmos de análise com backtracking (ou CYK,
    reveja a seção \ref{hierarquiaDeChomsky}) precisam ser utilizados para construção da Árvore Sintática.
    Como mostrado para Máquinas de Turing Não~=Determinísticas na seção \ref{mecanismosReconhecedores},
    Analisadores com Backtracking também funcionam em pior caso,
    com tempo exponencial e
    podem escolher uma estratégia como Busca em Profundidade\footnote{
    Veja a \fullref{buscaEmLarguraEProfundidade} para saber mais.
    } para executar os Ramos de Computação Não~=Determinístico.


\subsection{Reduções e Derivações}
\label{reducoesEderivacoes}

    Diferente Máquinas Reconhecedoras específicas como Automatos Finitos,
    os analisadores recebem diretamente como entrada uma gramática de uma dada linguagem.
    Mas diferente de gramáticas e
    Analisadores LL(K),
    Analisadores LR(K) especificamente funcionam de modo contrário.
    Eles operam por meio de Reduções ao invés de Derivações como no caso das Gramáticas e
    Analisadores LL(K) \cite{sipserBook}.

    Uma Derivação acontece quando uma regra de produção como ``$S \Rightarrow a a $'' de uma gramática expande e
    tem~=se como resultado ``$a a$'' a partir do símbolo de origem ``$S$''.
    Já uma Redução acontece quanto a dada regra de produção como ``$S \Rightarrow a a $'' de uma gramática reduz e
    tem~=se como resultado ``$S$'' a partir do símbolo de origem ``$a a$''.

    Tanto Derivações quanto Reduções podem ser descritas em termos que quantos passos são necessários para que se possa sair de um ponto até outro \cite{ahoCompilerDragonBook}:
    \begin{enumerate}%[nosep,nolistsep]
        \item Quanto um derivação é denotada como ``$S \Rightarrow a a $'',
        isso significa que somente um passo é necessário para sair do símbolo inicial ``$S$'' e
        chegar no símbolo final ``$a a$''.
        \item Quanto um derivação é denotada como ``$S \xRightarrow{*} a a $'',
        isso significa que são necessários,
        desde zero (nenhum) até infinitos passos para sair do símbolo inicial ``$S$'' e
        chegar no símbolo final ``$a a$''.
        \item Quanto um derivação é denotada como ``$S \xRightarrow{+} a a $'',
        isso significa que são necessários,
        desde um passo até infinitos passos para sair do símbolo inicial ``$S$'' e
        chegar no símbolo final ``$a a$''.
    \end{enumerate}

    Para reduções,
    estas mesmas condições se aplicam,
    mas em ordem reversa,
    i.e., $\Leftarrow$, $\xLeftarrow{*}$ e $\xLeftarrow{+}$,
    ao invés de $\Rightarrow$,
    $\xRightarrow{*}$ e
    $\xRightarrow{+}$.
    Enquanto gramáticas são geradores de palavras que partem do símbolo inicial da gramática até gerarem uma palavra da linguagem,
    Analisadores Ascendentes como LR(K) são reconhecedores de palavras.

    Diferente de gramáticas,
    Analisadores Ascendentes partem de uma palavra da linguagem até chegarem no símbolo inicial da gramática,
    consumindo toda a palavra de entrada e
    chegando em um Estado de Aceitação.
    Já Analisadores Descendentes como LL(K),
    partem do símbolo inicial da gramática até consumirem toda palavra de entrada,
    também chegando um em Estado de Aceitação.

    Ambos os Analisadores Ascendentes ou
    Descendentes,
    terminam no final do processo,
    gerando toda a Árvore de Derivação.
    Entretanto,
    caso no final do processo,
    não chegue~=se em um Estado de Aceitação,
    i.e.,
    no símbolo inicial da gramática.
    Tem~=se somente a construção de uma Árvore de Derivação partial \cite{allStarAntlr}.

    No caso dos Analisadores Ascendentes,
    será uma floresta de árvores,
    por que somente no final da análise,
    com a chegada ao símbolo inicial da gramática,
    completa~=se custura de todas a árvores que foram parcialmente construídas durante o processo de análise (\textit{Bottom~=Up}).

    Já no caso dos Analisadores Descendentes,
    não existe uma floresta de árvores.
    Como parte~=se diretamente do símbolo inicial da gramática,
    a Árvore de Derivação desde o começo é construído como sendo uma única árvore (\textit{Top~=Down}).


\subsection{Analisadores LR(K)}

    Como pode ser observado na Figura \ref{fig:pictures/LinguagensDeterministicas.png},
    existem Gramáticas SLR(K) que não são Gramáticas LL(K) por que para uma gramática ser LL(K),
    ela precisa respeitar 3 propriedades,
    \begin{inparaenum}
        \item Não possuir Recursão a Esquerda,
        \item Estar fatorada e
        \item $\forall\; A\, \in\, V_n\; |\; A\,
                \xRightarrow{*}\, \varepsilon\,
                \land\, First(A)\, \cap\, Follow(A) = \varnothing$
    \end{inparaenum}
    \cite{ahoCompilerDragonBook}.

    Entretanto,
    Gramáticas LR(K), LALR(K) e
    SLR(K) não precisam de nenhuma dessas restrições.
    No caso da Recursão a Esquerda,
    o algoritmo de criação da Tabela de Análise Sintática da Gramática LR(K),
    LALR(K) ou SLR(K),
    não possui o problema de entrar em um loop infinito assim como acontecem com as Gramáticas LL(K),
    portanto aceitando~=se Gramáticas com Recursão a Esquerda.

    Uma vez que Analisadores LR(K) requerem uma quantidade de memória exponencial \cite{complexityOfLRKTesting} ao tamanho da gramáticas de entrada para operar,
    \citeonline{lalrDeRemer1982} criaram os Analisadores LALR(K)\footnote{
    Do inglês, \textit{Look~=Ahead} LA(K) LR(0),
    onde LR(0) é um Analisador LR(K) com $K=0$
    }
    e SLR(K)\footnote{
    Do inglês, \textit{Simple LR(K) parser}
    }
    com o objeto de viabilizar a implementação de Analisadores Ascendentes Determinísticos.

    Gramáticas de Linguagens Determinísticas são chamadas de LR,
    por que todas as Linguagens Determinísticas são reconhecidas por Analisadores LR(K),
    uma vez que \citeonline{knuthLrParser1965} provou que todas as Gramáticas Determinísticas são aceitas por um Analisador LR(K).

    Assim,
    além da hierarquia de Chomsky,
    também classifica~=se as gramáticas de acordo com o tipo de analisador que reconhece as linguagens representadas por elas.
    Como mostrado na Figura \ref{fig:pictures/LinguagensDeterministicas.png},
    nem todas as Gramáticas Livre de Contexto são de Determinísticas e
    uma gramática é Determinística somente se ela pode ser reconhecida por um Analisador LR(K).

    Portanto uma maneira fácil de decidir se uma dada gramática é determinística ou
    não,
    é tentar construir a sua tabela de um Analisador LR(K).
    Caso consiga~=se construir com sucesso (sem conflitos) a Tabela de Análise Sintática \cite{ahoCompilerDragonBook},
    a gramática é LR(K),
    caso contrário a gramática não é determinística.

    A mesma técnica pode ser aplicada no caso de analisadores menos poderosos como LALR(K),
    entretanto,
    uma vez que não se consiga construir a Tabela de Análise Sintática,
    não se pode ter certeza se dada gramática é ou não determinística.


\subsection{Análise Semântica}

    Usualmente,
    somente depois que a Árvore Sintática é construída,
    realiza~=se o processo de Análise Semântica \cite{ahoCompilerDragonBook},
    i.e.,
    a verificação da corretude do programa escrito em relação os aspectos Não~=estruturais,
    por exemplo,
    é sintaticamente correto escrever a declaração de uma mesma variável duas vezes ou
    mais.

    Entretanto,
    para algumas linguagens é semanticamente errado redeclarar uma variável duas vezes ou
    mais.
    O Analisador Sintático representado por uma Gramática Livre de Contexto não tem poder suficiente para realizar tais verificações devido as limitações desse tipo de gramática,
    que restringem~=se a estrutura do programa e
    não a seu significado (semântica).

    Nem todas as linguagens podem ser analisadas completamente em diferentes etapas,
    como Análise Léxica, Sintática e Semântica. Muitas vezes,
    estas três etapas acontecem em paralelo como realizado na implementação do compilador da Linguagem C \cite{jourdan2017,whyCcannotBeParsedWithALR1Parser}.

    A Gramática da Linguagem C não é Livre de Contexto devido as ambiguidades (conhecido também como Não~=Determinismo) existentes como a expressão ``\textit{x * y ;}''.
    Tal sentença pode ser ou
    a declaração de um ponteiro chamado \textit{y} do tipo \textit{x},
    ou a multiplicação de dois números armazenados nas variáveis \textit{x} e
    \textit{y},
    portanto ela não pode ser aceita por um Analisador LR(K) tradicional.

    Uma otimização que o compilador C faz para poder fazer o Analisador ``Determinístico'' da linguagem C,
    e assim saber se a expressão ``\textit{x * y ;}'' trata~=se de de uma mera multiplicação ou
    a declaração de uma variável,
    é exatamente a realização simultânea da Análise Léxica,
    Sintática e
    Semântica.
    Uma vez que um novo \textit{token} é reconhecido,
    ele é alimentado para o Analisador Sintático,
    que também o alimenta para o Analisador Semântico.

    Assim,
    o Analisador Sintático é capaz de consultar a Tabela de Símbolos \cite{ahoCompilerDragonBook} e
    descobrir se dado token ou
    tratar~=se de um tipo ou
    uma variável numérica.
    Entretanto,
    requer~=se cuidado sobre como estas alterações são feitas,
    pois pode~=se pensar que as gramáticas de todas as linguagens de programação são ``Livres de Contexto'' e
    Determinísticas.
    E uma vez que a gramática não é mais Livre de Contexto ou
    Determinística,
    pode~=se mover Aspectos Sensíveis ao Contexto para o Analisador Semântico,
    assim,
    deixando a gramática somente com aspectos determinísticos.


\subsection{Alterações nos Analisadores Sintáticos}

    Dependendo de como o Analisador Sintático de Gramáticas Livre de Contexto é alterado,
    o conjunto de gramáticas aceitos por tal analisador pode deixar de serem Livres de Contexto.
    As gramáticas somente continuarão Livre de Contexto caso estas alterações sejam somente mover checagens da etapa de Análise Sintática para a etapa de Análise Semântica sem realizar alterações no Analisador Sintático.

    Quanto se adiciona suporte a Aspectos Sensíveis ao Contexto \cite{contextSensitiveParsing} a Gramáticas Livre de Contexto por meio de alterações do Analisador Sintático,
    como feito no Analisador da Linguagem C,
    o analisador da gramática deixa de ser Livre de Contexto,
    suportando assim,
    algumas Gramáticas Sensíveis ao Contexto e\slash{}ou também algumas Gramáticas Não~=Determinísticas.

    Note que,
    a pesar disso não impede~=se que a gramática da Linguagem C,
    como mostrado na seção anterior,
    seja analisada com eficiência.
    Mas isso deixa a brechas para que ela possa não ser analisada com eficiência.
    A diferença para um analisador onde a gramática é inteiramente Livre de Contexto,
    é que elas tem performance \textit{garantida} pela sua Classe de Complexidade (Veja seção \ref{classesDeComplexidade}).

    Sintaxe e
    Semântica de Linguagens são completamente ortogonais.
    Gramáticas de Linguagens Irrestritas\footnote{
    Não a linguagem no qual elas representam,
    mas a própria gramática em si \cite{finiteAutomataTuringComplete}
    }
    podem ser Turing Completas\footnote{
    A Turing Completude acontece quando uma dada linguagem pode simular o funcionamento completo de uma Máquina de Turing
    }
    devido a sua equivalência com Máquinas de Turing e
    são capazes de realizar qualquer operação computacional.
    Mas,
    isso não pode ser confundido com as \textit{Strings} ou
    Programas gerados por essas gramáticas \cite{areThereDomainSpecificLanguages}.

    Tais programas podem ou
    não ser Turing Completos.
    Do lado oposto,
    até Linguagens Regulares podem gerar programas que são Turing Completos,
    mesmo que seu dispositivo reconhecedor equivalente,
    os Automatos Finitos,
    não tenham Turing Completude\footnote{
    Caso isso esteja confuso,
    reveja a Figura \ref{fig:pictures/HierarquiaDeChomsky.png} e
    note que de todas as Linguagens,
    quem tem Turing Completude são as Linguagens Irrestritas,
    enquanto Automatos Finitos são um subconjunto das Máquinas de Turing \cite{finiteAutomataTuringComplete}
    }
    \cite{turingCompleteRegularLanguages,finiteAutomataTuringComplete}.

    Na seção \ref{sec:software_implementation},
    será mostrado a implementação de uma Gramática ``Livre de Contexto'' em um Analisador LALR(1),
    onde Aspectos Sensíveis ao Contexto serão analisados pelo Analisador Semântico,
    tal como feito na implementação do Compilador da Linguagem C apresentado.
    Mas com a diferença de que utiliza~= um Analisador LALR(1) genérico,
    ao contrário de um analisador feito exclusivamente para a linguagem alvo.

    Este Analisador LALR(1),
    possui suporte a pequenos ``\textit{\englishword{hacks}}'' ou
    otimizações que permitem adicionar alguns aspectos Sensíveis ao Contexto ao Analisador LALR(1).
    Assim,
    as gramáticas aceitas por esse analisador incluem somente algumas Gramáticas Não~=Determinísticas,
    não incluindo todas as Gramáticas Livre de Contexto Ambíguas ou
    Sensíveis ao Contexto devido a limitações das alterações do algoritmo de Análise LALR(1) \cite{larkContextualLexer}.


\section{\advisor{Compiladores e }{}Classes de Complexidade}
\label{classesDeComplexidade}

    Como um todo,
    o conjunto de Linguagens Regulares pode ser considerado com complexidade linear\footnote{
    Complexidade linear é um caso particular de complexidade polinomial onde o grau do Polinômio é 1,
    i.e.,
    $\Theta(n)$.
    Aprenda mais sobre complexidade linear com \citeonline{cormenIntroductionToAlgorithms,computationalComplexityAuroraBarak}.
    }
    em tempo computacional para determinar de dada palavra pertence ou
    não a linguagem,
    por que toda Gramática Regular Não~=Determinística pode ser convertida em uma Gramática Regular Determinística \cite{sipserBook}.

    Infelizmente isso não é verdade para Gramáticas Livres de Contexto,
    por que Gramáticas Livre de Contexto Determinísticas $\Theta(n)$ e
    Não~=Determinísticas não são equivalentes.
    Gramáticas Não~=Determinísticas possuem complexidade exponential,
    quando analisadas por um Analisador com Backtracking.
    Em contra~=partida,
    Gramáticas Livre de Contexto Não~=Determinísticas também podem ser analisadas em tempo polinomial $\Theta(n^3)$ utilizando algoritmos de parsing tal como CYK (seção \ref{hierarquiaDeChomsky} e
    \citeonline{larkContextualLexer}).


\advisor{}{%
\subsection{Complexidade Computacional com Computadores Quânticos}

    Com a exceção de alguns problemas específicos \cite{theGoodAndBadQuantumComputing},
    a execução probabilística de Computadores Quânticos \cite{nonlinearQuantumComputers},
    baseados nas leis da Física Quântica \cite{dicke1963QuantumPhysicsIntroduction},
    podem cortar\footnote{
    Devido as probabilidades envolvidas,
    somente um ou
    alguns dos ramos de computação serão seguidos durante a execução do Algoritmo Quântico,
    pelo Computador Quântico.
    }
    caminho ``pulando'' ramos de Computação Não~=Determinísticos (da computação Clássica) com a superposição quântica.
    Assim,
    conseguindo resolver alguns problemas que são exponenciais,
    em tempo polinomial ao tamanho da entrada,
    utilizando algoritmos específicos para computadores quânticos \cite{quantumComputerSurvey,quantumSimulatorChagas}.

    Esta é a gama de problemas nos quais Computadores Quânticos são úteis \cite{quantumComputingForNonPhysicists},
    não sendo assim,
    substitutos completos da Computação Tradicional (ou Clássica) \cite{efficientQuantumComputation},
    somente otimizadores na resolução de alguns problemas que podem ser otimizados devido as propriedades específicas\slash{}probabilísticas das leis Física Quântica \cite{churchTuringQuantumComputer}.

    Pode~=se confundir Computadores Quânticos como equivalentes a Analisadores Não~=Determinísticos devido as nomenclaturas utilizadas.
    Enquanto analisadores são Não~=Determinísticos devido à ambiguidades nas gramáticas de entrada,
    Computadores Quânticos são Não Determinísticos devido à serem baseado em modelos Probabilísticos,
    i.e.,
    Computadores Quânticos não são equivalentes a Analisadores Não~=Determinísticos devido a sua execução ser probabilística \cite{polynomialQuantumComputers,probabilisticQuantumComputation,quantumSimulatorChagas}.

    Diferente dos Computadores Tradicionais,
    Computadores Quânticos são construídos com base nas leis da Física Quântica,
    que são radicalmente diferentes das Leis da Física Tradicional ou
    Clássica, i.e.,
    as Leis de Newton.
    As Leis da Física Clássica regem os elementos muitos grandes na escala galáxias,
    planetas, células e
    virus \cite{halliday2013fundamentals}.
    Já as Leis da Física Quântica regem as elementos muito pequenos na escala de átomos,
    elétrons, prótons, fótons e
    \textit{quarks} \cite{dicke1963QuantumPhysicsIntroduction}.
}

\subsection{Complexidade Teórica $versus$ Real}

    Na Figura \ref{fig:pictures/ParserNonDeterministic.png},
    encontra~=se uma Árvore de Computação de um Analisador Não~=Determinístico.
    Diz~=se que que o tempo de execução de um Analisador Não~=Determinístico é Não~=Determinístico Polinomial $NP$\footnote{
    Do inglês, \textit{Non~=Deterministic Polynomial Time},
    comumente conhecida pela pergunta,
    $P \stackrel{?}{=} NP$, i.e.,
    a classe de problemas com complexidade de tempo polinomial,
    está estritamente contida na classe de problemas $NP$ (Não~=Determinísticos Polinomiais) \cite{computationalComplexityAuroraBarak}?
    }
    ao tamanho da entrada,
    por que um Analisador Não~=Determinístico executa simultaneamente todos os ramos de Computação Não~=Determinísticos \cite{hopcroftBook}.

    Como mostrado na Figura \ref{fig:pictures/ParserNonDeterministic.png},
    após a cada um dos passo de computação 1,
    2, 3 e 4,
    todos os 15 ramos de computação foram concluídos.
    Cada um desses passos é corresponde a um item a ser analisado na entrada do programa.
    E esta computação,
    acontece em tempo Não~=Determinístico Polinomial,
    com expoente de $n$ igual a $1$,
    i.e.,
    $n^1$.
    \begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{pictures/ParserNonDeterministic.png}
    \caption[Árvore de Computação com 4 Passos de um Problema da Classe $NP$]{Árvore de Computação com 4 Passos de um Problema da Classe $NP$ -- Fonte Própria}
    \label{fig:pictures/ParserNonDeterministic.png}
    \end{figure}

    O que torna a computação Não~=Determinística\footnote{
    E pertencente a classe dos problemas Não~=Determinístico Polinomial.
    } é o fato de cada um dos itens 1,
    2, 3 e 4 da entrada,
    permitirem simultaneamente a escolha de mais de um caminho na escolha do próximo estado do analisador,
    i.e.,
    mais de um Ramo de Computação,
    devido a ambiguidades da gramática de entrada \cite{antlrBookTerrentParr}.

    Nesse contexto,
    $P$ representa o conjunto de problemas resolvidos tempo Determinístico Polinomial (por Máquinas de Turing Determinísticas),
    enquanto $NP$ o conjunto de Problemas resolvido em tempo Não~=Determinístico Polinomial (por Máquinas de Turing Não~=Determinísticas).
    Assim,
    um problema Não~=Determinístico Polinomial somente pode ser resolvido por uma Máquinas de Turing Determinística em tempo exponencial.

    O tempo de execução será linear ao tamanho da entrada caso o Analisador Não~=Determinístico seja de uma Linguagem Regular e
    implementado através de um Automato Finito.
    O tempo de execução será polinomial ao tamanho da entrada caso o Analisador Não~=Determinístico seja de uma Linguagem Livre de Contexto Ambígua (Gramática Não~=Determinística) e
    implementado através de algum algoritmo com tempo polinomial como CYK \cite{allStarAntlr}.

    Como já explicado nas observações da Figura \ref{fig:pictures/HierarquiaDeChomsky.png},
    existem duas classes distintas de complexidade para Gramáticas Livre de Contexto Não~=Determinísticas.
    Quando faz~=se uma Análise de uma Gramáticas Livre de Contexto Não~=Determinística,
    tem~=se como resultado várias possíveis Árvores de Derivação\footnote{
    Como a gramática é Não~=Determinística,
    existem muitas possíveis Árvores de Derivação,
    (devido à ambiguidade da gramática).
    }.

    Algoritmos de construção das Árvores de Derivação com Backtracking para Gramáticas Livre de Contexto Não~=Determinística,
    possuem tempo exponencial de execução.
    Já algoritmos como CYK,
    que simplesmente dizem se dada palavra pertence ou
    não a linguagem,
    possuem complexidade polinomial ao tamanho da palavra de entrada \cite{hopcroftBook}.


\subsection{Mecanismos Reconhecedores}
\label{mecanismosReconhecedores}

    Uma vez que o conjunto de Linguagens Determinísticas LR(K) (com tempo linear) está contida no conjunto das Linguagens Livres de Contexto,
    não considera~=se tempos Análise Lineares ou
    Polinomiais de execução para Linguagens Sensíveis ao Contexto ou
    Irrestritas,
    por que tudo o que é eficiente é Livre de Contexto e
    Determinístico.

    Algoritmos de Análise para essas outras classes de Linguagens serão exponenciais em pior caso \cite{contextSensitiveParsing} e
    quando analisados por dispositivos equivalentes a Máquinas de Turing Não~=Determinísticas terão no mínimo tempo polinomial\footnote{
    Quando fala~=se de complexidade de tempo polinomial para Máquinas Não~=Determinísticas,
    resulta~=se em uma complexidade de tempo exponencial ao simular o funcionamento dessa Máquina Não~=Determinística em um computador,
    ou seja,
    a Real Complexidade do problema termina sendo exponencial,
    enquanto teoricamente a complexidade é polinomial.
    Veja as figuras \ref{fig:pictures/ParserNonDeterministic.png} e
    \ref{fig:pictures/ParserDeterministic.png} e
    as compare.
    }
    de execução.

    Máquinas de Turing Não~=Determinísticas que resolvem os problemas da Classe $NP$ em tempo polinomial não existem fisicamente,
    portanto sua complexidade de tempo reduzida não pode ser alcançada e
    seu tempo de execução é exponential,
    pois para simular o funcionamento de uma Máquina de Turing Não~=Determinística,
    utiliza~=se uma Máquina de Turing Determinística\footnote{
    Máquinas de Turing Determinísticas são equivalentes aos computadores de propósito geral
    }
    \cite{sipserBook,turingMachinesRoyer}.

    Assim,
    Máquinas de Turing Determinísticas e
    Não~=Determinísticas são equivalentes,
    pois sempre é possível simular o funcionamento de uma Máquina de Turing Não~=Determinística,
    utilizando uma Máquina de Turing Determinística \cite{hopcroftBook}.

    Na Figura \ref{fig:pictures/ParserDeterministic.png},
    encontra~=se a mesma Árvore de Computação apresentada na Figura \ref{fig:pictures/ParserNonDeterministic.png},
    mas com a diferença de que desta vez utiliza~=se uma Máquina de Turing Determinística ao contrário de uma Máquina de Turing Não~=Determinística.
    Com isso,
    ao invés de um tempo polinomial ao tamanho da entrada,
    tem~=se um tempo exponential ao tamanho da entrada.
    \begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{pictures/ParserDeterministic.png}
    \caption[Árvore de Computação com 15 Passos]{Árvore de Computação com 15 Passos -- Fonte Própria}
    \label{fig:pictures/ParserDeterministic.png}
    \end{figure}

    Para que uma Máquina de Turing Determinística possa processar uma Gramática Não~=Determinística,
    é necessário execute cada um dos ramos de computação.
    Já Máquinas de Turing Não~=Determinísticas\footnote{
    Máquinas de Turing da classe $NP$,
    somente existem teoricamente
    }
    executam simultaneamente todos os ramos de computação Não~=determinísticos,
    conseguindo assim, desempenho linear ou
    polinomial ao tamanho da entrada compondo os problemas da classe $NP$ (com tempo Não~=Determinístico Polinomial) \cite{hopcroftBook}.


\subsection{Busca em Largura e Profundidade}
\label{buscaEmLarguraEProfundidade}

    Quando uma Máquina de Turing Determinística é utilizado para simular o funcionamento de uma Máquina de Turing Não~=Determinística,
    ela precisa decidir como escolher executar os Ramos de Computação Não~=Determinísticos \cite{sipserBook}.
    Duas principais abordagens distintas e
    conhecidas\footnote{
    Além dessas duas abordagens,
    existem muitas outras técnicas que podem ser cridas como misturas dessas duas estratégias extremas,
    como heurísticas e inteligências artificias
    }
    são a Busca em Largura\footnote{
    Do inglês, \textit{Breadth-First Search (BFS)}
    }
    e Busca em Profundidade\footnote{
    Do inglês, \textit{Depth-First Search (DFS)}
    }.
    Os algoritmos funcionamento desses tipos de busca são detalhadas em \citeonline{cormenIntroductionToAlgorithms}.

    Cada uma delas apresenta suas vantagens e
    desvantagens.
    Uma vantagem da Busca em Profundidade é possibilidade de ``sorte'',
    caso o primeiro ramo não~=determinístico que escolhe~=se seja uma solução para o problema,
    i.e.,
    leve o analisador a um estado de aceitação,
    mas ao mesmo tempo de pode~=se ter ``sorte'',
    pode~=se ter o ``azar'' de que o primeiro ramo não~=determinístico seja um ramo infinito de computações que nunca levarão o analisador à um estado de aceitação.

    A Figura \ref{fig:pictures/ParserDeterministic.png} mostrou um exemplo de uso do algoritmo de Busca em Profundidade.
    Já na Figura \ref{fig:pictures/ParserDeterministicBreadth.png},
    encontra~=se a variação de execução de um Analisador Determinístico que utilizou o algoritmo de Busca em Largura.
    \begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{pictures/ParserDeterministicBreadth.png}
    \caption[Árvore de Computação com 15 Passos utilizado Busca em Largura]{Árvore de Computação com 15 Passos utilizado Busca em Largura -- Fonte Própria}
    \label{fig:pictures/ParserDeterministicBreadth.png}
    \end{figure}

    Tanto o algoritmo de Busca em Largura quanto Busca em Profundidade,
    não precisam exatamente seguir resolvendo o problema pela esquerda ou
    direita.
    O que importa é a sua característica de avançar até o fim de algum dado ramo de computação,
    ou seguir executando todos os ramos que fazem parte de um mesmo nível de computação \cite{cormenIntroductionToAlgorithms,efficientBreadthFirstSearch}.
}

