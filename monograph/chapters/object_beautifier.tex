

% Is it possible to keep my translation together with original text?
% https://tex.stackexchange.com/questions/5076/is-it-possible-to-keep-my-translation-together-with-original-text
\chapter{Uma Ferramenta de Formatação}
\label{software_implementation}

Neste capítulo será explicado o funcionamento e
implementação de uma nova ferramenta de formatação.
A proposta desta nova ferramenta é permitir que usuários possam entrar com a gramática de qualquer linguagem,
por meio de uma metagramática para então formatar o código~=fonte da linguagem descrita pela gramática.


\section{Uma Gramática de Gramáticas}

Na \fullref{introducaoGramaticas},
foi explicado o que são gramáticas.
Mas,
como gramáticas podem ser expressadas?
Isso depende de como seu analisador foi implementado\advisor{.}{,
sendo assim,
um detalhe de implementação.%
} \advisor{Analisadores}{Usualmente,
analisadores} seguem uma notação comum como EBNF\footnote{
Do inglês,
\textit{Extended Backus–Naur Form} uma extensão do padrão BNF.
}\cite{teachingEbnf,antlrBookTerrentParr},
\advisor{que diverge de acordo com detalhes de implementação.
}{%
que não difere muito de um analisador para outro,
exceto por detalhes de implementação específicos de cada analisador.
}

Para realizar a implementação da nova ferramenta de Formatação de Código,
foi realizado a construção de uma nova gramática de gramáticas de uma nova linguagem chamada de ``ObjectBeauty'',
uma metalinguagem \cite{compilersCompilerMetaLanguage}.
Na \typeref{MyWorflowForLarkTraduzido},
é apresentado o fluxo de uso comum para um analisador.
Neste processo,
o desenvolvedor da linguagem escreve a gramática de especificação desta linguagem,
que é entregue a algum Analisador e
gera~=se um Compilador para tal linguagem.
\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{MyWorflowForLarkTraduzido.png}
\caption[Fluxo de uso comum de um Analisador]{Fluxo de uso comum de um Analisador -- Fonte Própria \cite{larkErrorRecovery}}
\label{MyWorflowForLarkTraduzido}
\end{figure}

Já este trabalho faz um uso fora do comum.
Como mostrado na \typeref{MyWorflowForLarkTraduzido2},
primeiro especifica~=se uma metalinguagem que será utilizada pelos usuários da nova ferramenta de Formatação de Código.
Para escrever esta nova metalinguagem,
utilizou~=se o Analisador Lark \cite{larkContextualLexer}.
Usualmente o Analisador Lark é utilizado somente como um gerador de compiladores (\typeref{MyWorflowForLarkTraduzido}),
entretanto neste contexto Lark é utilizado como um compilador de compiladores (\typeref{MyWorflowForLarkTraduzido2}).
Para este trabalho,
foi realizado um \textit{fork} \cite{overviewOfGitHubForks,mayTheForkBeWithYou,collaborationAmongGitHubUsers} do Analisador Lark,
renomeado o Analisador Lark para ``pushdown''\footnote{%
O código~=fonte do \textit{fork} pode ser encontrado em \url{https://github.com/evandrocoan/pushdownparser}.
}.
\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{MyWorflowForLarkTraduzido2.png}
\caption[Uso feito pela nova ferramenta de Formatação de Código]{Uso feito pela nova ferramenta de Formatação de Código -- Fonte Própria \cite{larkErrorRecovery}}
\label{MyWorflowForLarkTraduzido2}
\end{figure}

Foi realizado um \textit{fork} do Analisador Lark para poder~=se realizar pequenas alterações que facilitam o entendimento do funcionamento interno da ferramenta como adição de logs e
alterações nos algoritmos de iteração nas árvores geradas pela ferramenta.
Por isso,
em alguns lugares do código~=fonte será encontrado o nome ``pushdown'' ao invés de ``lark''.
Já em outros,
continua~=se sendo chamado Lark de Lark para simplificar a retrocompatibilidade com a biblioteca original e
facilitar a realização da integração de novos updates vindos do repositório original do Analisador Lark para o \textit{fork} realizado.

Em vez de permitir com que o usuário final da aplicação opere diretamente com o Analisador da \typeref{MyWorflowForLarkTraduzido},
foi criado uma nova metagramática como mostrado nas \typeref{MyWorflowForLarkTraduzido2}.
Esta nova metagramática simplifica o processo de escrita de gramáticas ao criar uma nova especificação de gramáticas,
somente com os recursos necessários para se possa trabalhar com formatação de código~=fonte.
A final,
não é objetivo deste trabalho fazer a análise completa de programas,
pela sua sintaxe e
semântica e
gerar código~=binário executável.

Na \typeref{ParsersPublicAudienceTraduzido},
pode~=se encontrar uma relação entre o funcionamento das diversas partes da ferramenta de Formatação de Código e
a audiência alvo.
Basicamente existem três grupos distintos de usuários ou
audiência:
\begin{inparaenum}[1)]
\item quem escreve ou
desenvolve a ferramenta de Formatação de Código proposta por este trabalho e
defini as regras da metalinguagem (especificada pela sua metagramática,
i.e.,
a gramática de gramáticas),
\item quem escreve ou
desenvolve gramáticas de linguagens para serem formatados de acordo com as regras da metalinguagem e
\item quem escreve ou
desenvolvedor programas de computador e
deseja realizar a formatação de seus códigos~=fonte.
\end{inparaenum}%
\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{ParsersPublicAudienceTraduzido.png}
\caption[Relacionamentos entre os Diferentes Públicos deste Projeto]{Relacionamentos entre os Diferentes Públicos deste Projeto -- Fonte Própria \cite{larkErrorRecovery}}
\label{ParsersPublicAudienceTraduzido}
\end{figure}

Até este ponto,
já falou~=se de metagramática e
metalinguagem com a exceção dos metaprogramas \cite{tradeoffsInMetaprogramming}.
Nas \typeref{MyWorflowForLarkTraduzido2,ParsersPublicAudienceTraduzido},
por simplificação foram omitidos o relacionamento dos metaprogramas com a metagramática e
metalinguagem.
Metaprogramas fazem parte da entrada do metacompilador (\typeref{MetacompilerMetagrammarMetaprogram}) junto com a metagramática para gerar um novo compilador (ou Formatador de Código).
Neste trabalho,
os metaprogramas serão as gramáticas que serão utilizadas pelos formatadores de código~=fonte.

Os metaprogramas (ou gramáticas) são entradas diretas do metacompilador (o Analisador Lark na \typeref{MyWorflowForLarkTraduzido2}).
Na \typeref{ParsersPublicAudienceTraduzido},
não pode~=se ver diretamente que as gramáticas das linguagens serão os metaprogramas,
mas o quadro em azul mais a esquerda ligado por linhas pontilhadas explica que os erros léxicos e
sintáticos nas gramáticas de entrada serão mostrados pelo Analisador Lark.
Isso acontece por que as gramáticas (ou metaprogramas) são entradas diretamente no Analisador Lark.

Na \typeref{MetacompilerMetagrammarMetaprogram},
encontra~=se uma extensão da \typeref{MyWorflowForLarkTraduzido2},
e pode~=se ver claramente as relações entre Metagramáticas,
Metacompiladores e Metaprogramas. Por simplificação,
mostra~=se o nodo ``Arvore de Sintaxe'' sem explicitamente falar sobre sua Análise Semântica e
propriamente a construção do Compilador (ou do Formatador de Código).
Vale lembrar que trata~=se de um Compilador de Compiladores,
e não um Compilador de Analisadores.
Por isso vemos que os Metaprogramas (ou gramáticas) são entradas diretas dos Metacompilador,
e não do Formatador de Código.
\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{MetacompilerMetagrammarMetaprogram.png}
\caption[Relação entre Metagramáticas, Metacompiladores e Metaprogramas]{Relação entre Metagramáticas, Metacompiladores e Metaprogramas -- Fonte Própria \cite{larkErrorRecovery}}
\label{MetacompilerMetagrammarMetaprogram}
\end{figure}

Esta não é a primeira vez que uma metagramática com simplificações foi escrita.
Em trabalhos como \citeonline{rustSublimeTextSyntaxSyntec,sublimeTextSyntax,vsCodeSyntaxHighlighthing} foram realizados as mesmas simplificações aqui apresentadas.
Existem algumas diferenças técnicas da metagramática deste trabalho com as dos recém apresentados.
Como por exemplo,
a implementação desta metagramática ainda não suporta a classificação do mesmo trecho de código~=fonte por múltiplos tipos de escopo \cite{vsCodeSyntaxHighlighthing}.

Foi escolhido a criação de uma nova metagramática por que as implementações de metagramáticas já existentes como \citeonline{rustSublimeTextSyntaxSyntec,vsCodeSyntaxHighlighthing}
\begin{inparaenum}[1)]
\item não são capazes de reconhecer todas as características de todas as linguagens de programação e
\item não possuem sintaxe própria,
i.e.,
elas utilizam de outras linguagens como YAML,
XML e
JSON para fazer a especificação da metagramática.
\end{inparaenum}
Assim,
fazendo a especificação de uma nova metagramática,
é possível adaptar~=se a especificação da sintaxe das gramáticas de acordo as necessidades específicas sem ter que depender de características de outras linguagens como YAML,
XML ou
JSON.


\subsection{Escopos}

Na \typeref{TexMateScopes} é mostrado na primeira linha o trecho de código~=fonte ``function f1 () \{'' e
nas demais linhas são apresentados as diversas classificações de escopos aplicados a cada um dos trechos do código~=fonte de amostra.
Por exemplo, a palavra ``function'' possui simultaneamente os escopos
\begin{inparaenum}[1)]
\item ``source.js''
\item ``meta.function.js'' e
\item ``storage.type.function.js''.
\end{inparaenum}
\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{TexMateScopes.png}
\caption[Exemplo de Classificação de Código~=Fonte com Múltiplos Escopos]{Exemplo de Classificação de Código~=Fonte com Múltiplos Escopos -- Fonte \citeonline{vsCodeSyntaxHighlighthing}}
\label{TexMateScopes}
\end{figure}

Os nomes utilizados na \typeref{TexMateScopes} podem ser qualquer texto que usuário especificador daquela gramática desejar.
Entretanto,
pode~=se perceber que o nome dos escopos recém apresentados aparentam seguir um padrão.
Por conversão,
desenvolvedores de gramáticas para os editores de texto como \citeonline{sublimeTextSyntax,vsCodeSyntaxHighlighthing},
seguem uma conversão de nomes para que as utilizações dos escopos gerados pelas gramáticas sejam compatíveis entre si.

Fazendo o uso desta convenção,
as gramáticas ficam compatíveis com um maior número de arquivos de temas onde são especificados os nomes dos escopos serão utilizados para especificar as cores a serem utilizadas pelo editor de texto.
Para mais informações sobre a utilização de arquivos de temas em editores de texto veja \citeonline{sublimeTextScopeNaming,vsCodeSyntaxHighlighthing}.


\section{Metalinguagem}
\label{metalinguagemGrammar}

Como já explicado na seção anterior,
uma metagramática é gramática de gramáticas e
foi utilizado o Analisador Lark \cite{larkContextualLexer} como um metacompilador ou
compilador de compiladores.
Nesta seção será explicado a como a metalinguagem (especificada pela metagramática) utilizada foi construída,
começando com o seu símbolo inicial.
No \typeref{simboloInicialDaMetagramatica},
defini~=se que o programa é constituído de três grandes áreas,
que devem acontecer uma em sequencia da outra:
\begin{enumerate}
\item A produção ``preamble\_statements'' define características globais da gramática como um nome,
e um escopo que será atribuído a toda gramática.
\item A produção ``language\_construct\_rules'' define qual será o símbolo inicial da gramática.
Em comparação com linguagens de programação como ``C'',
ele pode ser considerado similar ao método ``main''.
\item A produção ``miscellaneous\_language\_rules'' permite a definição de diversos contextos\footnote{
Contexto refere~=se a um bloco de operadores ou
instruções como ``include'' e
``match''.
} com grupos de produções da gramática (\fullref{definicaoDeGramatica}),
que podem ser incluídos a partir do símbolo inicial da gramática definido no item ``language\_construct\_rules''.
\end{enumerate}%
\begin{lstlisting}[caption={Simbolo Inicial da Metagramática ``ObjectBeauty''},label={simboloInicialDaMetagramatica},style=yaml_style]
language_syntax: _NEWLINE? preamble_statements _NEWLINE?
                    language_construct_rules _NEWLINE?
                    ( miscellaneous_language_rules _NEWLINE? )*
                    _NEWLINE?

preamble_statements: ( (
                        target_language_name_statement
                        | master_scope_name_statement
                        | constant_definition
                    ) _NEWLINE )+

language_construct_rules: "contexts" ": " indentation_block
miscellaneous_language_rules: /[^:\n]+/ ": " indentation_block

target_language_name_statement: "name" ": " free_input_string
master_scope_name_statement: "scope" ": " free_input_string
\end{lstlisting}

Entre os \typeref{exemploDeGramaticaPawn1,exemploDeGramaticaPawn2,exemploDeGramaticaPawn3,exemploDeGramaticaPawn4},
encontra~=se pequenos exemplos de gramáticas escritas na metalinguagem ``ObjectBeauty'' brevemente apresentada.
No \typeref{exemploDeGramaticaPawn1},
encontra~=se a definição do símbolo inicial da gramática da linguagem sendo descrita (pela metagramática) e
pode~=se ver a metalinguagem sendo utilizada para definir uma linguagem chamada de ``Abstract Machine Language''.
Por padrão,
toda gramática ``ObjectBeauty'' precisa ter um contexto inicial ou
símbolo inicial chamado de ``contexts''.

O \typeref{exemploDeGramaticaPawn1} faz uso dos operadores ``include'' e
``match''.
O operador ``include'' serve incluir partes de outras gramáticas ou
mesmo gramáticas inteiras no contexto da gramática atual.
Entretanto,
a implementação de ``include'' realizada neste trabalho somente consegue realizar includes de contextos definidos no mesmo arquivo.

No exemplo \typeref{exemploDeGramaticaPawn1},
o operador ``include'' está incluindo contextos da gramática atual que serão definidas mais tarde neste mesmo arquivo.
Já o operador ``match'' utilizado no final serve para realizar propriamente o reconhecimento do programa de entrada e
atribuir a ele o escopo ``constant.boolean.language.pawn''.

Mais tarde,
as informações de escopo atribuídas por operadores como ``match'' e
``captures'' serão utilizadas pelo formatador de código~=fonte.
Com estas informações,
o Formatador de Código será capaz de realizar as operações de formatação somente sobre os trechos de código~=fonte que o usuário definir.
Realizando assim,
a formatação seletiva de código~=fonte,
contrário da formatação total de código~=fonte como acontece nos demais trabalhos (\typeref{performanceDoFormator}).
\begin{lstlisting}[caption={Exemplo de Gramática -- Símbolo Inicial},label={exemploDeGramaticaPawn1},style=yaml_style]
name: Abstract Machine Language
scope: source.sma

contexts: {
    include: parens
    include: numbers
    include: check_brackets

    match: (true|false) {
        scope: constant.boolean.language.pawn
    }
}
\end{lstlisting}

No \typeref{exemploDeGramaticaPawn2},
é introduzido o uso dos operadores ``push'',
``meta\_scope'' e
``pop''.
O operadores ``push'' e
``pop'' são responsáveis por manter uma pilha de contextos que permite aplicar um mesmo escopo por várias linhas utilizado o operador ``meta\_scope''.

A diferença entre o operador ``scope'' e
``meta\_scope'' é que o operador ``scope'' atribuí o escopo diretamente ao texto reconhecido pelo um operador ``match''.
Já o operador ``meta\_scope'' permite aplicar o escopo a todo o texto desde o primeiro até o último ``match'',
que desempilha com o operador ``pop'',
o contexto empilhado inicialmente com um ``push''.
\begin{lstlisting}[caption={Exemplo de Gramática -- Contextos},label={exemploDeGramaticaPawn2},style=yaml_style]
parens: {
    match: \( {
        scope: parens.begin.pawn
        push: {
            meta_scope: meta.group.pawn
            match: \) {
                scope: parens.end.pawn
                pop: true
            }
            include: numbers
        }
    }
}
\end{lstlisting}

No \typeref{exemploDeGramaticaPawn3},
é introduzido o uso do operador ``captures''.
O operador ``captures'' atribuí simultaneamente diversos escopos com uma única expressão regular.
Cada um dos números listados equivalem a um dos grupos de captura \cite{expressionGrammarsWithRegexLikeCaptures} da expressão regular utilizada no operador ``captures''.

O operador ``scope'' pode ser considerado um caso especial do operador ``captures'' quando utiliza~=se o grupo de captura 0,
que refere~=se a toda a expressão regular encontrada.
Por exemplo,
ao invés de utilizar o operador``scope:
algo'',
poderia~=se utilizar equivalentemente o operador ``captures:
0.
algo''.
\begin{lstlisting}[caption={Exemplo de Gramática -- Grupos de Captura},label={exemploDeGramaticaPawn3},style=yaml_style]
numbers: {
    match: '(\d+)(\.\{2\})(\d+)' {
        captures: {
            0: constant.numeric.pawn
            1: constant.numeric.int.pawn
            2: keyword.operator.switch-range.pawn
            3: constant.numeric.int.pawn
        }
    include: numeric
}
\end{lstlisting}

No \typeref{exemploDeGramaticaPawn4},
é mostrado mais alguns exemplos de uso do operador ``match'' classificando diversos tipos de numéricos (da linguagem sendo descrita pela gramática).
É importante notar que a ordem no qual os operadores como ``match'' aparecem é importante.
Ao realizar o reconhecido o programa de entrada utilizando esta gramática,
a Árvore de Sintaxe Abstrata\footnote{%
Do inglês (AST), Abstract Syntax Tree.
} \cite{ahoCompilerDragonBook} será interpretada diversas vezes,
iniciando no símbolo inicial até chegar ao último símbolo da gramática.

O processo de interpretação irá reiniciar infinitamente até que nenhum texto seja mais consumido por nenhum dos operadores da gramática.
Assim,
uma vez que um trecho de código~=fonte já foi classificado,
ele será ignorado quando os próximos operadores forem aplicados,
evitando assim que o programa execute infinitamente.
\begin{lstlisting}[caption={Exemplo de Gramática -- Tipos numéricos},label={exemploDeGramaticaPawn4},style=yaml_style]
numeric: {
    match: ([-]?0x[\da-f]+) {
        scope: constant.numeric.hex.pawn
    }
    match: \b(\d+\.\d+)\b {
        scope: constant.numeric.float.pawn
    }
    match: \b(\d+)\b {
        scope: constant.numeric.int.pawn
    }
}
\end{lstlisting}

Por fim,
no \typeref{exemploDeGramaticaPawn5} é mostrado um exemplo não relacionado com formatação de código~=fonte.
A construção utilizada é comum para gramáticas que serão utilizadas para realizar a aplicação de cores em editores de texto \cite{vsCodeSyntaxHighlighthing}.
Com ela é possível colorir o código~=fonte como invalido no editor de texto,
uma vez que a inconsistência foi encontrada na linguagem sendo analisada.

Construções como a do \typeref{exemploDeGramaticaPawn5} funcionam usualmente quando elas são a última regra da gramática.
Uma vez que todas as regras que consomem o programa de entrada e
o classifica em escopos terminam seu trabalho,
não deveria existir mais nenhum texto ser reconhecido.
Caso exista,
ou a gramática não estava preparada para reconhecer todo o programa de entrada,
ou estes trechos de código~=fonte são frutos de algum erro no programa de entrada.
\begin{lstlisting}[caption={Exemplo de Gramática -- Reconhecimento de Erros},label={exemploDeGramaticaPawn5},style=yaml_style]
check_brackets: {
    match: \) {
        scope: invalid.illegal.stray-bracket-end
    }
}
\end{lstlisting}


\section{Analisador Semântico}

Depois que um metaprograma da metalinguagem apresentada na seção anterior é analisada pelo Analisador Lark,
o Analisador Lark entrega a Árvore de Sintaxe da gramática da linguagem sendo descrita pelo metaprograma (\typeref{MetacompilerMetagrammarMetaprogram}).
Todas as verificações de corretude da sintaxe da gramática são verificadas pelo Analisador Lark,
com base na metagramática da metalinguagem.
Portanto,
somente resta ser implementado o Analisador Semântico para verificar se a linguagem descrita respeita as regras semânticas da metalinguagem explicadas na seção anterior,
\nameref{metalinguagemGrammar}.

Neste trabalho,
o Analisador Semântico recebe como entrada a Árvore de Sintaxe do programa de entrada,
e uma vez que o Analisador Semântico termina seu trabalho,
ele devolve Árvore de Sintaxe Abstrata completa.
Então,
utilizando a Árvore de Sintaxe Abstrata,
realiza~=se a formatação de código~=fonte recebendo um programa de entrada e
as configurações do formatador (\typeref{MetacompilerMetagrammarMetaprogram}).

No \typeref{semanticAnalizerConstructor},
pode~=se ver o construtor do Analisador Semântico.
Pode~=se estranhar seu construtor não receber como parâmetro a Árvore de Sintaxe,
entretanto,
a ela não é passada pelo construtor mas sim por um método chamado ``transform(tree)''.
Esta é uma característica do Analisador Lark utilizado.
A função ``transform(tree)'' do Analisador Lark simplesmente inicia a análise do programa visitando todos os nós da Árvore de Sintaxe,
partindo das folhas até chegar na raíz.
\begin{lstlisting}[caption={Construtor do Analisador Semântico},label={semanticAnalizerConstructor},style=mypython]
class TreeTransformer(pushdown.Transformer):
    """
        Transforms the Derivation Tree nodes into meaningful string representations,
        allowing simple recursive parsing and conversion to Abstract Syntax Tree.
    """

    def __init__(self):
        ## Saves all the semantic errors detected so far
        self.errors = []

        ## Saves all warnings noted so far
        self.warnings = []

        ## Whether the mandatory/obligatory global scope name statement was declared
        self.is_master_scope_name_set = False

        ## Whether the mandatory/obligatory global language name statement was declared
        self.is_target_language_name_set = False

        ## Can only be one scope called `contexts`
        self.has_called_language_construct_rules = False

        ## Pending constants declarations
        self.constant_usages = {}

        ## Pending constants usages
        self.constant_definitions = {}

        ## A list of miscellaneous_language_rules include contexts defined for duplication checking
        self.defined_includes = {}

        ## A list of required includes to check for missing includes
        self.required_includes = {}

        ## A list of regular expressions used on match statements,
        ## for validation when the constants definitions are completely know
        self.pending_match_statements = []

        ## Responsible for calculating all open and close commands scoping
        self.open_blocks = {}
        self.indentation_level = 0
        self.indentation_blocks = []
\end{lstlisting}

A visita dos nodos pela função ``transform(tree)'' acontece simplesmente chamado métodos que a classe ``TreeTransformer''\footnote{%
Definido no \typeref{semanticAnalizerConstructor}.
} define e
que possuem os mesmos nomes que os símbolos não=terminais definidos pela metagramática.
Então,
cada nodo ou
função deve retornar qual será o novo nodo que irá o substituir na Árvore de Sintaxe.
Assim,
no final do processo,
um a um,
cada nodo da Árvore de Sintaxe será convertido para um nodo da Árvore de Sintaxe Abstrata.

Um jeito fácil de excluir um nodo da Árvore de Sintaxe é simplesmente definir uma função com o nome de seu não~=terminal que returna ``null''.
Por exemplo,
o trecho da metagramática apresentado no \typeref{simboloInicialDaMetagramatica} possui alguns os símbolos não terminais como ``preamble\_statements'' e
``language\_construct\_rules''. Então,
para estes dados símbolos,
serão chamados os métodos da classe ``TreeTransformer'' que possuem os nomes ``preamble\_statements'' e
``language\_construct\_rules''.

Caso não existam os métodos ``preamble\_statements'' e
``language\_construct\_rules'' na classe ``TreeTransformer'',
os nós ``preamble\_statements'' e
``language\_construct\_rules'' da Árvore de Sintaxe não serão visitados e
``poderão'' ser excluídos da Análise Semântica (mas não da Árvore de Sintaxe Abstrata).
Note que,
nodos não existentes classe ``TreeTransformer'' não serão excluídos da Árvore final,
mas eles serão mantidos intactos,
a não ser que algum outro nodo os altere diretamente.

Mesmo que não existam os métodos ``preamble\_statements'' e
``language\_construct\_rules'' definidos na classe ``TreeTransformer'',
eles também pode ser visitados diretamente a partir de algum nodo pai deles ou
até algum de seus filhos.
Inclusive,
esta foi uma das alterações realizadas no fork ``pushdown'' do Analisador Lark.
Por padrão,
ao iterar pela árvore,
o Analisador Lark somente passa como parâmetro da função o nodo correspondente ao método atualmente sendo chamado e
uma lista de filhos.
Entretanto,
``pushdown'' também passa um terceiro parâmetro que é uma referência para o nó raíz da árvore e
mantém a variável ``parent'' como um atributo da árvore que aponta para o nó pai do nó atual.

O formatador de código~=fonte não é composto somente uma parte única e
altamente acoplada, mas pelo contrário,
um conjunto de partes altamente coesas e
completamente independentes onde cada uma dessas partes recebe a Árvore de Sintaxe Abstrata do Analisador Semântico,
para então realizar a formatação do programa de entrada junto com as configurações que esta parte aceita.


\subsection{Performance}
\label{performanceDoFormator}

Continuamente chamar diversos algoritmos independentes possui uma grande a perda de performance em comparação com os formatadores de código~=fonte apresentados no \fullref{source_code_beautifiers}.
Estes formatadores tem como principal características realizar a formatação de código~=fonte em uma única passada,
i.e.,
a Árvore de Sintaxe de programa de entrada é completamente reconstruída,
para então ser serializada novamente em texto de acordo com as configurações de formatador.

Ao leitor mais desatento,
pode parecer que então não existe muita diferença entre a ferramenta de formatação proposta neste trabalho para as já existentes.
Entretanto,
estre trabalho permite que o usuário entre com a gramática da linguagem a ser formatada,
diferentes dos outros trabalhos onde esta gramática já vem junto do formatador.
Formadores de código~=fonte como apresentados na \fullref{source_code_beautifiers} são construído programando~=se as produções da gramática diretamente no código~=fonte do formatador (Descendentes Recursivos,
reveja a \fullref{gramaticasVersusLinguagens}).

Ao não permitir que o usuário possa entrar com a gramática do programa,
restringe~=se o formatador a somente funcionar com as gramáticas que foram programadas dentro do seu código~=fonte.
Uma vez que o usuário da ferramenta precisa programar ela para ter suporte a sua linguagem,
isso dificulta a adição do suporte de novas linguagens de formatação,
pois precisa~=se programar as suas gramáticas dentro do código~=fonte do formatador.


\section{Formatador de Código}

No \typeref{construtorDoFormatador},
pode ser encontrado o construtor do formatador de código~=fonte.
Comparando~=o com o construtor do Analisador Semântico \typeref{semanticAnalizerConstructor},
pode~=se notar que algumas diferenças.
Em ambos os casos,
o processo todo se completará ao percorrer toda a árvore.
No caso do Analisador Semântico,
a Árvore de Sintaxe.
E no caso do Formatador de Código,
a Árvore de Sintaxe Abstrata.

Diferentemente do Analisador Semântico,
o Formatador de Código faz herança do tipo ``Interpreter'' em vez de ``Transformer''.
A diferença é simples,
``Interpreter'' visita a árvore partindo das folhas até chegar na raiz visitando todos os nodos filhos,
já ``Transformer'' visita a árvore partindo da raíz até chegar nos nodos pais,
i.e.,
ele não visita os nodos filhos automaticamente como ``Transformer'' faz.

``Interpreter'' também recebe diretamente no construtor qual será a árvore que ele irá iterar sobre.
Nos demais aspectos,
``Interpreter'' funciona igual ao ``Transformer'',
exceto no ponto onde ``Transformer'' cria no final do processo uma nova árvore,
enquanto ``Interpreter'' não cria árvore alguma.
O parâmetro chamado ``program'' que o construtor ``Transformer'' recebe,
é o programa a ser formatado pelo formatador.
No final processo,
``Interpreter'' terá em sua variável ``self.program'' o programa completamente formatado.
\begin{lstlisting}[caption={Construtor do Formatador},label={construtorDoFormatador},style=mypython]
class Backend(pushdown.Interpreter):

    def __init__(self, tree, program, settings):
        super().__init__()
        self.tree = tree
        self.program = ParsedProgram( program, settings )

        ## A list of lists, where each list saves all the matches performed by
        ## the last match_statement on scope_name_statement
        self.last_match_stack = []

        ## This is set to False every push statement, and set to True, after
        ## every match statement. This way we can know whether there is a match
        ## statement after a push statement.
        self.is_there_push_after_match = False
        self.is_there_scope_after_match = False

        self.cached_includes = {}
        self.cache_includes( tree )

        self.visit( tree )
        log( 4, "Tree: \n%s", tree.pretty( debug=0 ) )
\end{lstlisting}

Enquanto ``Interpreter'' é responsável por somente ``passear'' pela Árvore de Sintaxe Abstrata,
a classe ``ParsedProgram'' \typeref{construtorDeParsedProgram} é responsável por realmente fazer a formatação de código~=fonte de acordo com a instruções vindas da Árvore de Sintaxe Abstrata.
No final do processo,
``ParsedProgram'' terá na variável ``new\_program'' todos os pedaços do program programa formatado.

Uma vez que ``Interpreter'' termina de construir todos os pedaços de código~=fonte formatado,
a função ``get\_new\_program'' irá juntos dos os pedaços e
salvá~=los na variável ``cached\_new\_program'',
para evitar ter que recalcular o novo programa toda vez que se pedir~=se sua nova versão.
\begin{lstlisting}[caption={Construtor de ParsedProgram},label={construtorDeParsedProgram},style=mypython]
class ParsedProgram(object):
    """
        Represents a program as chunks of data as (text_chunk_start_position,
        text_chunk).
    """

    def __init__(self, program, settings):
        super().__init__()
        self.initial_size = len( program )
        self.program = program
        self.settings = OrderedDict( sorted( settings.items(), key=lambda item: len( str( item ) ) ) )

        self.new_program = []
        self.cached_new_program = []
        log( 4, "program %s: `%s`", len( str( self.program ) ), self.program )
\end{lstlisting}

