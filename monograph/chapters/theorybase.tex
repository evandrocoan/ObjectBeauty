

% Is it possible to keep my translation together with original text?
% https://tex.stackexchange.com/questions/5076/is-it-possible-to-keep-my-translation-together-with-original-text
\chapter{\lang{Theory base}{Fundamentação Teórica}}
\label{fundamentacaoTeorica}

De acordo com o funcionamento de muitos Formatadores de Código (Veja o \fullref{source_code_beautifiers}) e
da ferramenta que foi desenvolvida (veja \fullref{software_implementation}),
foi explicado resumidamente toda a teoria necessária para construção de compiladores,
incluindo as classes de complexidade para medidas da eficiência dos compiladores.
Seguindo um currículo acadêmico de um curso de Ciências da Computação,
este resumo seria o equivalente as disciplinas de:
\begin{inparaenum}[1)]
\item Teoria da Computação;
\item Linguagens Formais, e;
\item Construção de Compiladores.
\end{inparaenum}%


\section{Compiladores e Tradutores}
\label{compiladoresEtradutores}

\lang{%
    This work aims to propose a translator \cite{generatingInterpretiveTranslators},
    where the input and
    output languages are the same language.
    Such translation objective is to change the language representational structure,
    but without affecting the language lex,
    syntactic or semantics, i.e.,
    the language meaning.

    This program class is commonly know as text formatters.
    The differential from this work from others is the goal of a single expandable tool,
    capable of manipulating all existent and
    future programming languages,
    based on the use of deterministic \cite{introductionToContextFreeGrammars} and
    controlled nondeterministic
    % \cite{TODO:section explaning what does controlled means}
    context free grammars.
}{%
    Em linguagens formais,
    tradutores são ferramentas que operam realizando a transformação de um programa de entrada,
    em um programa de saída \cite{generatingInterpretiveTranslators}.
    Diferente de um compilador,
    a linguagem de destino da ``tradução'' é do \textbf{mesmo nível} que a linguagem de origem.
    Por exemplo,
    dado um programa de entrada em C++ e
    um programa de saída em Java,
    tem~=se um processo de tradução (\typeref{ProcessoTraducao}).
    \advisor{A tradução é diferente de um processo de compilação,
    que é dotado de mais etapas \cite{translatorGenerationCompilier}.
    }{Pelo outro lado,
    dado um programa de entrada em C++ e
    um programa de saída em \textit{Assembly},
    tem~=se um processo de compilação \cite{translatorGenerationCompilier}.
    }
    \begin{figure}[!htb]
    \caption{Processo de Tradução}
    \label{ProcessoTraducao}
    \centering
    \includegraphics[width=1.0\textwidth]{ProcessoTraducao.png}
    \fonte{Própria, baseado em \citeonline{ahoCompilerDragonBook}}
    \end{figure}
}

No processo de compilação ou
tradução,
um Analisador Léxico cria múltiplos \textit{tokens}.
Um \textit{token} é composto por diversos atributos como a posição e
o \textit{lexema}, i.e.,
a sequencia de caracteres que este \textit{token} representa no programa de entrada.
O \textit{lexema} também pode ser conhecido como os símbolos terminais da gramática.
Uma vez que o programa é ``\textit{tokenizado}'' pelo Analisador Léxico,
o Analisador Sintático constrói a Árvore Sintática do programa.

Utilizando a Árvore Sintática do programa de entrada,
o tradutor constrói uma nova Árvore Sintática correspondente a Árvore Sintática da linguagem do programa destino,
utilizada para construir o código~=fonte do programa destino.
Em um processo de compilação,
não seria criado uma nova Árvore Sintática como no processo de tradução,
mas sim a geração de código objeto ou
binário \cite{ahoCompilerDragonBook}.

Analisadores Sintáticos podem ser Ascendentes\footnote{
Do inglês, \textit{Bottom~=Up}.
}
ou Descendentes\footnote{
Do inglês, \textit{Top~=Down}.
}.
Devido a essa característica ambos possuem as suas vantagens e
desvantagens.
Um Analisador Ascendente realiza a construção da Árvore Sintática das folhas até a raíz,
o contrário de um Analisador Descendente que realiza a construção da Árvore Sintática a partir da raíz até as folhas\footnote{
Como pode ser observados em seus nomes,
ambos os analisadores tanto da familia LL (Descendentes,
\textit{Left-to-right, Leftmost derivation}) ou LR (Ascendentes, \textit{Left~=to~=right,
Rightmost derivation}) fazem a leitura do programa de entrada da esquerda para a direita.
}.

Uma vantagem de um Analisador Ascendente é o suporte de uma maior classe de Gramáticas Determinísticas.
Uma vantagem de um Analisador Descendente é a facilidade da recuperação de erros em relação aos Analisadores Ascendentes\footnote{
Conceito abordado na
\fullref{analisadoresSintaticos}.
}
\cite{sippu1982,lr1ErrorRecovery,errorRecoveryForYaccParsers,repairingSyntaxErrorsInLR,larkJosefGrosch,errorsInLRParsers}.


\section{Gramáticas}
\label{introducaoGramaticas}

Gramáticas são conjuntos de regras que definem uma linguagem.
Uma gramática é definida por quatro componentes,
como serão apresentados a seguir.
Para estes componentes,
considere que os símbolos:
\begin{inparaenum}[1)]
\item $V_n$ representa o conjunto de não~=terminais;
\item $V_t$ representa o conjunto de terminais e;
\item $V = V_n \cup V_t$
\end{inparaenum}.
\begin{enumerate}%[nosep,nolistsep]
    \item \advisor{O}{Um} conjunto $V_t$ de símbolos terminais\advisor{ (também chamados
    de \textit{tokens} ou símbolos do alfabeto da linguagem).
    Cada terminal corresponde a um símbolo presente na linguagem.
    }{,
    chamados algumas vezes de ``\textit{tokens}'' devido a sua forte conexão.
    Cada terminal corresponde a um símbolo presente no alfabeto da linguagem.
    }%
    Durante a Análise Léxica,
    os símbolos terminais serão utilizados definir os lexemas que são a base principal dos \textit{tokens}.
    Na composição da Árvore Sintática,
    os ``\textit{tokens}'' ou símbolos terminais,
    serão usualmente as folhas da Árvore Sintática (a não ser em casos específicos,
    como por exemplo,
    quando a gramática possui símbolos inúteis \cite{hopcroftBook});

    \item \advisor{O}{Um} conjunto $V_n$ de símbolos não~=terminais (algumas vezes chamados de ``variáveis sintáticas'').
    Não~=terminais servem para agrupar vários não~=terminais e\slash{}ou terminais.
    Na composição da Árvore Sintática,
    os símbolos não~=terminais sempre serão os nós da Árvore Sintática\footnote{
    Desde que a gramática da linguagem não contenha símbolos inúteis,
    i.e.,
    todos os símbolos da gramática são férteis e
    permitem a geração de palavras além do conjunto vazio $\varnothing$ \cite{hopcroftBook}.
    }.
    Como restrição,
    para evitar ambiguidades entre quais são os símbolos terminais e
    não~=terminais,
    a intersecção entre o conjunto de símbolos terminais e
    não~=terminais é sempre vazia,
    i.e.,
    $V_n \cap V_t = \varnothing$;

    \item \label{definicaoDeGramatica}Um conjunto de produções $P$.
    Uma produção consiste em uma dupla elementos.
    O primeiro elemento é a cabeça ou
    lado esquerdo e
    representa a substituição ou
    consumo que será feito no programa de entrada.
    Ele é obrigatoriamente constituído de no mínimo um símbolo não~=terminal e
    um ou mais não~=terminais ou
    terminais.
    O segundo elemento é a cauda ou
    lado direito da produção,
    composto de terminais e\slash{}ou não~=terminais.
    Formalmente define~=se o conjunto de produções de uma gramática pela seguinte regra,
    onde ``*'' representa o operador de fechamento do conjunto \cite{hopcroftBook}.
    Independente do tipo de gramática,
    está é a definição formal do que é uma gramática em teoria da computação e
    linguagens formais,
    sendo o tipo mais genérico de gramática:
    $$P = \{\; \alpha ::= \beta \;|\; \alpha \in V^* V_n V^* \land \beta \in V^* \;\}$$

    \item Um símbolo inicial selecionado a partir do conjunto de símbolos não~=terminais.
    O símbolo inicial é utilizado para definir qual será a raíz da Árvore Sintática,
    e.g.,
    uma das últimas regras de produção utilizada para terminar o reconhecimento do programa de entrada em um Analisador Ascendente,
    e uma das primeira regras utilizada em um Analisador Descendente ou
    gerar~=se palavras desta linguagem\footnote{
    Processo natural quanto um Analisador Sintático realiza o reconhecimento de um programa de entrada.
    Para mais informações,
    veja a \fullref{reducoesEderivacoes}.
    }.
\end{enumerate}

No \typeref{code:ExemploDeGramaticaLark},
é possível ver um exemplo real de gramática aceito pelo Analisador Lark.
Esta é uma gramática de uma linguagem finita que aceita 3 palavras:
\begin{inparaenum}[1)]
\item ``token sem nome'';
\item ``token com nome'' e;
\item ``token com outro nome''.
\end{inparaenum}%
No Analisador Lark,
quando um token é declarado diretamente como ``token sem nome'',
ele irá ser descartado da Árvore Sintática.
Como pode ser visto na \typeref{Figure:ArvoresDosTokens1},
a árvore sintática do programa ``token sem nome'',
irá conter somente o símbolo inicial da gramática.
Nas \typeref{Figure:ArvoresDosTokens1,Figure:ArvoresDosTokens2,Figure:ArvoresDosTokens3},
pode ser visto a Árvore Sintática de cada uma das 3 palavras da linguagem do \typeref{code:ExemploDeGramaticaLark}.
\begin{code}
\caption{Exemplo de Gramática Utilizada pelo Formatador de Código}
\label{code:ExemploDeGramaticaLark}
\begin{minted}[xleftmargin=2em]{python}
import pushdown

parser = pushdown.Lark(
    """
        simbolo_inicial: "token sem nome" | TOKEN_COM_NOME | nodo_da_arvore
        TOKEN_COM_NOME: "token com nome"
        nodo_da_arvore: TOKEN_COM_OUTRO_NOME
        TOKEN_COM_OUTRO_NOME: "token com outro nome"
    """,

    start='simbolo_inicial',
    parser="lalr",
)

def parseit(program, filename):
    pushdown.tree.pydot__tree_to_png(
            parser.parse( program ), filename, "TB", debug=1, dpi=600 )

parseit( 'token sem nome',  "token_sem_nome.png" )
parseit( 'token com nome',  "token_com_nome.png" )
parseit( 'token com outro nome', "token_com_outro_nome.png" )
\end{minted}
\end{code}

A sintaxe da gramática utilizada no \typeref{code:ExemploDeGramaticaLark},
é uma adaptação especial do padrão EBNF que o Analisador Lark faz.
Símbolos que possuem todas as letras em ``MAIÚSCULA'' definem os símbolos terminais da gramática que aparecerão na Árvore Sintática.
Enquanto símbolos escrito todos em letras ``minúsculas'' definem os símbolos não~=terminais da gramática.
Para mais informações sobre a sintaxe de entrada de gramáticas do Analisador Lark,
consulte sua documentação \cite{larkGrammarReference,larkStyleCheat}.

A \typeref{Figure:ArvoresDosTokens1},
representa a Árvore Sintática completa da palavra ``token sem nome'',
que a linguagem da gramática do \typeref{code:ExemploDeGramaticaLark} aceita.
Como pode ser facilmente percebido,
ela é uma Árvore Sintática estranha.
Cadê o \textit{token}?
O \textit{token} da árvore foi descartado pelo Analisador Lark,
porque ele não está dentro de uma produção de \textit{token} com nome em letras ``MAIÚSCULAS''.
Este é um recurso do Analisador Lark,
que permite descartamos da Árvore Sintática \textit{tokens} que julgam~=se desnecessários aparecem na Árvore Sintática.
\begin{figure}[H]
\caption{Árvore do Programa ``token sem nome''}
\label{Figure:ArvoresDosTokens1}
\centering
% https://tex.stackexchange.com/questions/86350/includegraphics-maximum-width
\includegraphics[max width=0.2388\textwidth]{token_sem_nome.png}
\fonte{Própria}
\end{figure}

A \typeref{Figure:ArvoresDosTokens2},
representa a Árvore Sintática completa da palavra ``token com nome'',
que a linguagem da gramática do \typeref{code:ExemploDeGramaticaLark} aceita.
Diferente da Árvore Sintática da \typeref{Figure:ArvoresDosTokens2},
a Árvore Sintática da \typeref{Figure:ArvoresDosTokens2},
possui como nó folha a palavra ``token com nome''.
Porque na gramática da linguagem,
foi criado especificamente a produção ``\mintinline{antlr}{TOKEN_COM_NOME:
"token com nome"}'',
fazendo com que o Analisador Lark não descarte \textit{token} da Árvore Sintática.
\begin{figure}[H]
\caption{Árvore do Programa ``token com nome''}
\label{Figure:ArvoresDosTokens2}
\centering
\includegraphics[max width=0.799\textwidth]{token_com_nome.png}
\fonte{Própria}
\end{figure}

A \typeref{Figure:ArvoresDosTokens3},
representa a Árvore Sintática completa da palavra ``token com outro nome'',
que a linguagem da gramática do \typeref{code:ExemploDeGramaticaLark} aceita.
Diferente da Árvore Sintática das \typeref{Figure:ArvoresDosTokens1,Figure:ArvoresDosTokens2},
a Árvore Sintática da \typeref{Figure:ArvoresDosTokens3},
apresenta um nó intermediário chamado de ``nodo\_da\_arvore''.
O nó intermediário ``nodo\_da\_arvore'' é um exemplo de símbolo não~=terminal da gramática.
Usualmente,
os símbolos não~=terminais nunca são nós folhas das Árvores Sintáticas.
Entretanto,
caso a gramática de entrada possua símbolos inúteis \cite{hopcroftBook},
podem existir ramificações da Árvore Sintática na qual símbolos não~=terminais são nós folhas.
\begin{figure}[H]
\caption{Árvore do Programa ``token com outro nome''}
\label{Figure:ArvoresDosTokens3}
\centering
\includegraphics[max width=1.0\textwidth]{token_com_outro_nome.png}
\fonte{Própria}
\end{figure}

No \typeref{code:ExemploDeEstruturaDeGramaticaLark},
pode ser encontrado outro exemplo de gramática aceita pelo Analisador Lark.
Nas \typeref{Figure:palavra12,Figure:palavra1,Figure:palavra2,Figure:palavra3},
pode ser encontrado as 4 palavras da linguagem que esta gramática aceita.
Nas \typeref{Figure:palavra1,Figure:palavra2,Figure:palavra3},
pode~=se ver as palavras da linguagem (gramática do \typeref{code:ExemploDeEstruturaDeGramaticaLark}),
na qual correspondem exatamente aos símbolos do alfabeto da linguagem.
Já a \typeref{Figure:palavra12},
mostra como o conjunto de produções da gramática pode ser utilizado para montar a estrutura (sintaxe) da linguagem,
combinando os símbolos do alfabeto da linguagem.
\begin{code}
\caption{Exemplo de Gramática com uma Estrutura de Sintaxe}
\label{code:ExemploDeEstruturaDeGramaticaLark}
\begin{minted}[xleftmargin=2em]{python}
import pushdown

parser = pushdown.Lark(
    r"""
        simbolo_inicial: NUMERO1 NUMERO2 |  NUMERO3  | nao_terminal
        nao_terminal: NUMERO1 | NUMERO2
        NUMERO1: "1"
        NUMERO2: "2"
        NUMERO3: "3"
    """,

    start='simbolo_inicial',
    parser="lalr",
)

def parseit(program, filename):
    pushdown.tree.pydot__tree_to_png(
            parser.parse( program ), filename, "TB", debug=1, dpi=600 )

parseit( '1', "palavra1.png" )
parseit( '2', "palavra2.png" )
parseit( '3', "palavra3.png" )
parseit( '12', "palavra12.png" )
\end{minted}
\end{code}

A \typeref{Figure:palavra12},
representa a Árvore Sintática completa da palavra ``12'',
que a linguagem da gramática do \typeref{code:ExemploDeEstruturaDeGramaticaLark} aceita.
A \typeref{Figure:palavra12},
é um bom exemplo para demonstrar a diferença entre sintaxe e
semântica.
Gramáticas Livre de Contexto somente representam a estrutura de um programa (ou palavra) de uma linguagem.
O que é mostrado na \typeref{Figure:palavra12},
é a estrutura da palavra ``12'',
isto é,
como os símbolos ``1'' e
``2'' do alfabeto da linguagem são estruturados.
Já semanticamente (o significado),
da estrutura formada pelos símbolos ``1'' e
``2'' do alfabeto,
pode ser interpretado como o número ``12'' (doze),
representado estruturalmente pela Árvore Sintática da \typeref{Figure:palavra12}.
\begin{figure}[H]
\caption{Árvore da palavra ``12''}
\label{Figure:palavra12}
\centering
\includegraphics[max width=0.896\textwidth]{palavra12.png}
\fonte{Própria}
\end{figure}

A \typeref{Figure:palavra1},
representa a Árvore Sintática completa da palavra ``1'',
que a linguagem da gramática do \typeref{code:ExemploDeEstruturaDeGramaticaLark} aceita.
\begin{figure}[H]
\caption{Árvore da palavra ``1''}
\label{Figure:palavra1}
\centering
\includegraphics[max width=0.4435\textwidth]{palavra1.png}
\fonte{Própria}
\end{figure}

A \typeref{Figure:palavra2},
representa a Árvore Sintática completa da palavra ``2'',
que a linguagem da gramática do \typeref{code:ExemploDeEstruturaDeGramaticaLark} aceita.
\begin{figure}[H]
\caption{Árvore da palavra ``2''}
\label{Figure:palavra2}
\centering
\includegraphics[max width=0.4435\textwidth]{palavra2.png}
\fonte{Própria}
\end{figure}

A \typeref{Figure:palavra3},
representa a Árvore Sintática completa da palavra ``3'',
que a linguagem da gramática do \typeref{code:ExemploDeEstruturaDeGramaticaLark} aceita.
A Árvore Sintática da \typeref{Figure:palavra3},
apresenta a definição de um \textit{token} com o nome ``NUMERO3''.
\begin{figure}[H]
\caption{Árvore da palavra ``3''}
\label{Figure:palavra3}
\centering
\includegraphics[max width=0.4435\textwidth]{palavra3.png}
\fonte{Própria}
\end{figure}


\subsection{Hierarquia de Chomsky}
\label{sectionHierarquiaDeChomsky}

Todas as gramáticas que existem são no mínimo\footnote{
Caso contrário não serão gramáticas,
mas qualquer outra definição na qual a Teoria de Linguagens Formais e
Compiladores pode não se aplicar.
}
Gramáticas Tipo 0 \cite{ahoTheoryOfParsing,chomskyGrammars1956},
também conhecidas como Gramáticas Irrestritas porque não possuem nenhuma restrição de complexidade de tempo,
como os outros tipos de gramáticas a serem definidos nas próximas seções{}.
A partir da adição de restrições sobre a definição formal de gramática recém apresentada,
também pode~=se \advisor{compreender}{realizar diversas classificações como} a hierarquia de \citeonline{chomskyGrammars1956},
onde uma linguagem pode ser classificada como Regular,
Livre de Contexto,
Sensível ao Contexto e
Irrestrita (\typeref{FigureHierarquiaDeChomsky}).
\begin{figure}[!htb]
\caption{Hierarquia de Chomsky}
\label{FigureHierarquiaDeChomsky}
\centering
\includegraphics[width=1.0\textwidth]{HierarquiaDeChomsky.png}
\begin{minipage}{\textwidth} \footnotesize
*Para Gramáticas Regulares Determinísticas,
complexidade linear ao tamanho da palavra de entrada para determinar se uma dada palavra pertence ou
não à linguagem.
Para Gramáticas Regulares Não~=Determinísticas,
complexidade polinomial para construir as Árvores de Derivações e
determinar se dada palavra pertence ou
não a linguagem com algoritmos como CYK \cite{hopcroftBook,cykParsingAlgorithm}.
Por fim,
para Autômatos Finitos Não~=Determinísticos ou
Analisadores com Backtracking,
tempo exponencial.

**Para Gramáticas Livres de Contexto Determinísticas,
também conhecidas como LR(K),
complexidade linear ao tamanho da palavra de entrada (Veja a \fullref{gramaticasVersusLinguagens}).
Para Gramáticas Livre de Contexto Não~=Determinísticas,
vale o mesmo que para Linguagens Regulares Não~=Determinísticas logo acima,
mas no lugar de Autômatos Finitos Não~=Determinísticos,
utilizam~=se Máquinas de Pilha Não~=Determinísticas.

***Para verificar se uma dada sentença pertence ou
não a linguagem.
Veja \citeonline{complexityClasses,computationalComplexityAuroraBarak},
para aprender mais sobre Classes de Complexidade.
\end{minipage}
\fonte{Própria, baseado em \citeonline{sipserBook,ahoTheoryOfParsing,efficientNonDeterministicParsers,johnCocke}}
\end{figure}

Toda Gramática Regular ou
Livre de Contexto,
é também uma Gramática Irrestrita ou
Sensível ao Contexto,
uma vez que Gramáticas Livres de Contexto ou
Regulares são um subconjunto das Gramáticas Irrestritas ou
Sensíveis ao Contexto como apresentado na \typeref{FigureHierarquiaDeChomsky}.
Por isso,
também pode~=se chamar uma dada Gramática Regular de Irrestrita ou
Livre de Contexto.

Quando diz~=se que existe uma Gramática Livre de Contexto para uma dada linguagem,
pode~=se ter a impressão de que este é o melhor tipo de gramática,
i.e.,
o tipo mais eficiente em tempo computational na qual uma dada linguagem pode ser representada.
Entretanto,
precisa~=se tomar cuidado quando se fala sobre gramáticas e
linguagens.

Não se pode dizer que uma dada Linguagem é Livre de Contexto simplesmente porque existe uma Gramática Livre de Contexto para dada linguagem.
Pois também é preciso que esta gramática seja o tipo mínimo na qual esta linguagem pode ser escrita.
Sempre se pode escrever uma gramática menos eficiente do que o tipo mínimo de gramática que uma linguagem pode ser escrita.
Para saber se este tipo de gramática é o mínimo,
utiliza~=se o Lema do Bombeamento\footnote{
Do inglês, \textit{Pumping Lemma} \cite{hopcroftBook,sipserBook}.
}
para determinar e
provar formalmente que dada gramática é o tipo mínimo de gramática para dada linguagem.


\subsection{Gramáticas Regulares}

Gramáticas Regulares (também conhecidas como Tipo 3) são todas aquelas reconhecidas por Autômatos Finitos Determinísticos e\slash{}ou Não~=Determinísticos.
Gramáticas de Linguagens Regulares pela definição formal,
são todas aquelas nas quais todas as Produções $P$ da gramática possuem a seguinte forma:
$$ P = \{\; \alpha ::= a \beta \;|\; \alpha \in V_n \land a \in V_t
            \land \beta \in \{\; V_n \cup \varepsilon\; \} \;\} $$

\subsection{Gramáticas Livres de Contexto}

Gramáticas Livres de Contexto (também conhecidas como Tipo 2) \cite{hopcroftBook} são todas aquelas reconhecidas por Autômatos de Pilha Não~=Determinísticos.
Gramáticas de Linguagens Livre de Contexto pela definição formal,
são todas aquelas nas quais todas as Produções $P$ da gramática possuem a seguinte forma:
$$ P = \{\; \alpha ::= \beta \;|\; \alpha \in V_n \land \beta \in V^* \;\} $$


\subsection{Gramáticas Sensíveis ao Contexto}

Gramáticas Sensíveis ao Contexto (também conhecidas como Tipo 1) são todas aquelas reconhecidas por Autômatos Linearmente Limitados\footnote{
Do inglês,
Linear Bounded Automata \cite{fundamentalsOfTheoreticalComputerScience}.
},
que tratam~=se somente de Máquinas de Turing \cite{sipserBook} com Fita (ou memória) Finita.
Gramáticas de Linguagens Sensíveis ao Contexto pela definição formal,
são todas aquelas nas quais todas as Produções $P$ da gramática possuem a seguinte forma.
Onde os símbolos $\vert\alpha\vert$ e
$\vert\beta\vert$ significam o tamanho dos conjuntos $\alpha$ e
$\beta$,
respectivamente:
$$ P = \{\; \alpha ::= \beta \;|\; \alpha \in V^* V_n V^* \land \beta \in V^*
            \land \vert\alpha\vert \leq \vert\beta\vert \;\} $$


\subsection{Gramáticas Irrestritas}

Por fim,
as Gramáticas Irrestritas (também conhecidas como Tipo 0),
possuem a mesma definição do que a definição válida de uma gramática como apresentado anteriormente (no
\fullref{definicaoDeGramatica}).
Gramáticas Irrestritas são reconhecidas somente por Máquinas de Turing\footnote{
Máquinas de Turing possuem por definição fita (ou memória) ilimitada,
mas não infinita,
pois em um dado momento,
somente uma quantidade finita de símbolos podem estar na fita,
que continuamente pode crescer ilimitadamente.
},
e diferente das Gramáticas Sensíveis ao Contexto,
a Máquina de Turing não possui parada garantida.

Linguagens do Tipo 0 (ou Irrestritas) representam problemas indecidíveis e
que podem ser representados por procedimentos \cite{sipserBook}.
Já Linguagens do Tipo 1 (ou Sensíveis ao Contexto),
representam todos os problemas computáveis e
sua implementação pode ser representada por algoritmos\footnote{
Aprenda mais sobre decidibilidade e
computabilidade com \citeonline{turingMachinesRoyer,sipserBook}.
},
pois possuem parada garantida,
apesar de terem em pior caso,
tempo exponential ao contrário de tempo infinito,
como nas Linguagens Irrestritas.


\section{Analisadores Sintáticos}
\label{analisadoresSintaticos}

Analisadores são equivalentes à Mecanismos Reconhecedores como Autômatos Finitos,
Autômatos de Pilha ou
Máquinas de Turing.
No caso de outros Mecanismos como Autômatos Finitos,
o reconhecimento é feito a partir da especificação ou
construção do autômato que reconhece palavras de dada linguagem.
Ambos gramáticas e
autômatos são equivalentes e
existem algoritmos de conversão entre um e
outro \cite{hopcroftBook}.

Analisador Sintático\footnote{
Além de Analisadores Sintáticos (Gramáticas Livre de Contexto),
existem muitos outros como Analisadores Semânticos (Gramáticas Sensíveis ao Contexto) \cite{contextSensitiveParsing}.
}
é um nome dado para analisadores que recebem como entrada uma gramática que representa os aspectos estruturais de uma linguagem,
i.e.,
sua sintaxe \cite{ahoCompilerDragonBook}.
Analisadores Sintáticos possuem muito mais utilidade do que somente checar se a sintaxe do programa de entrada está correta,
uma vez que eles também podem gerar a Árvore Sintática do programa\footnote{
Como visto no começo desde capítulo na \fullref{compiladoresEtradutores}.
}
que é utilizada para realizar a análise semântica e
geração de código.


\subsection{Gramáticas $versus$ Linguagens}
\label{gramaticasVersusLinguagens}

É importante fazer a distinção entre Gramáticas Livre de Contexto e
as Linguagens Livre de Contexto.
\citeonline{parikh1966},
provou que existem linguagens nas quais não existem Gramáticas Não~=Ambíguas que representem estas linguagens.
Tais linguagens são conhecidas como Linguagens Inerentemente Ambíguas\footnote{
Do inglês,
\textit{Inherently Ambiguous Languages}.
Veja o que significa ambiguidade na \fullref{analiseSemantica}.
}
onde não existem Gramáticas Livre de Contexto Determinísticas capazes de representa~=las e
tais Linguagens somente podem ser reconhecidas por Analisadores com Backtracking \cite{ahoCompilerDragonBook} ou
Autômatos de Pilha Não~=Determinísticos.

A maior classe de Gramáticas Determinísticas suportadas por Analisadores Sintáticos são as Gramáticas LR(K)\footnote{
Do inglês, \textit{Left~=to~=right,
Rightmost derivation} em reverso com K símbolos de \textit{lookahead}.
\textit{Rightmost} significa que ao realizar as derivações,
escolhe~=se sempre o não~=terminal mais a direita.
}.
Analisadores LR(K) \cite{ahoCompilerDragonBook} são Ascendentes e
reconhecem um subconjunto das Linguagens Livre de Contexto (\typeref{LinguagensDeterministicas}).
Já os Analisadores LL(K)\footnote{
Do inglês, \textit{Left-to-right,
Leftmost derivation} com K símbolos de \textit{lookahead}.
\textit{Leftmost} significa que ao realizar as derivações,
escolhe~=se sempre o não~=terminal mais a esquerda.
}
são Descendentes \cite{antlrBookTerrentParr,llStarAntlr,allStarAntlr} e
reconhecem somente um subconjunto das Linguagens LR(K)\footnote{
Diz~=se que uma linguagem é LR(K) ou
LL(K) quando ela é reconhecida por este analisador.
}.

A \typeref{LinguagensDeterministicas},
não é inteiramente um Diagrama de Venn \cite{generalizedVennDiagrams},
inicialmente,
nas camadas mais externas,
ele é uma relação abstrata entre Linguagens Ambíguas e
Gramáticas Determinísticas.
O Conjunto das Gramáticas Livre de Contexto Determinísticas está contido dentro das Linguagens Livre de Contexto\footnote{
Também existem Gramáticas Sensíveis ao Contexto Determinísticas \cite{contextSensitiveParsing},
entretanto,
algoritmos de análise possuem em pior caso,
complexidade exponencial \cite{areContextSensitiveGrammarWithPolynomialTime}.
}.
O primeiro nível significa que todas as Linguagens Inerentemente Ambíguas\footnote{
É comum confundir~=se e
chamar Gramáticas de Inerentemente Ambíguas,
mas esse termo não existe para gramáticas.
Ou elas são Ambíguas ou
Não.
Somente uma linguagem pode ser Inerentemente Ambígua.
}
são representáveis somente por Gramáticas Ambíguas.

O segundo nível significa que Linguagens Não~=Inerentemente Ambíguas\footnote{
Somente utilizado para enfatizar o conjunto de Linguagens na qual existem Gramáticas Ambíguas e
Determinísticas (ou Não~=Ambíguas).
}
podem ser representadas por Gramáticas Ambíguas e\slash{}ou Determinísticas.
No terceiro nível encontra~=se as gramáticas que são mais importantes,
as Gramáticas Determinísticas\footnote{
As Gramáticas Determinísticas representam o conjunto de Linguagens que podem ser Analisadas Deterministicamente e
tais Linguagens também podem ser conhecidas como LR(K),
LR(K).
Reveja os parágrafos após a \typeref{FigureHierarquiaDeChomsky}.
},
que podem ser classificadas como LR(K),
LL(K), etc, i.e.,
de acordo com o tipo de analisador que pode ser construído sem conflitos em sua Tabela de Análise\footnote{
Do inglês, \textit{Parsing Table},
\cite{ahoCompilerDragonBook}.
}.
\begin{figure}[!htb]
\caption{Gramáticas Determinísticas \textit{versus} suas Linguagens}
\label{LinguagensDeterministicas}
\centering
\includegraphics[width=1.0\textwidth]{LinguagensDeterministicas.png}
\fonte{Própria, baseado em \citeonline{llVersusLrContainment,llContainmentInLalr,beatty1982,ahoCompilerDragonBook,grammarsAndTheMinimalParsers}}
\nota{%
    Apesar da fonte da figura ser o próprio autor deste texto,
    o conhecimento requirido para construir tão complexa figura não,
    requerendo pesquisa em várias fontes.
}
\end{figure}

É importante notar que usualmente o processo de análise por um analisador,
seja ele LR(K) ou
LL(K),
acontece em duas etapas.
Com a exceção dos Analisadores LL(K) que também podem ser facilmente construídos programaticamente\footnote{
Neste caso,
o analisador pode ser conhecido como Descendente Recursivo,
(do inglês,
Recursive Descent).
},
i.e.,
com o programador construindo manualmente como deve acontecer cada transição de estado do analisador \cite{ahoCompilerDragonBook}.

Na primeira etapa do analisador utilizam~=se algoritmos de construção da Tabela de Análise.
Quando a tabela está construída sem conflitos (este analisador portanto,
é determinístico),
entra em cena o algoritmo de análise na segunda etapa,
que utilizando a Tabela de Análise,
realiza o reconhecimento do programa de entrada.
Como única diferença entre os Analisadores LR(K),
LALR(K) e
SLR(K) é exatamente construção da Tabela de Análise,
ambos possuem a mesma complexidade de análise linear ao tamanho do programa\footnote{
Quando refere~=se a programa,
fala~=se da \textit{string} ou
texto que será analisado e
decidir se tal programa é um programa da linguagem que se está analisando.
Um ponto curioso,
caso o programa não seja aceito pelo analisador,
ele não é um programa com erros,
mas um programa inválido,
i.e.,
de uma outra linguagem,
que não é a linguagem que está sendo analisada.
Comumente ou
informalmente,
chamamos estes programas como programas com erros (de sintaxe).
}
de entrada que será analisado \cite{knuthLrParser1965,linearLL1AndLR1Grammars,generalContextFreeParsingAlgorithm}.

No caso de conflitos na Tabela de Análise,
a gramática não pode ser analisada deterministicamente e
algoritmos de análise com backtracking\footnote{
Ou algoritmos de tempo polinomial como CYK,
reveja a \fullref{sectionHierarquiaDeChomsky}.
}
precisam ser utilizados para construção da Árvore Sintática.
Como mostrado para Máquinas de Turing Não~=Determinísticas na \fullref{mecanismosReconhecedores},
Analisadores com Backtracking também funcionam em pior caso,
com tempo exponencial e
podem escolher uma estratégia como Busca em Profundidade\footnote{
Veja a \fullref{buscaEmLarguraEProfundidade} para saber mais.
} para executar os Ramos de Computação Não~=Determinístico.


\subsection{Reduções e Derivações}
\label{reducoesEderivacoes}

Diferente de máquinas específicas como Autômatos Finitos,
analisadores recebem diretamente como entrada uma gramática de uma dada linguagem.
Mas diferente de gramáticas e
Analisadores LL(K),
Analisadores LR(K) especificamente funcionam de modo contrário.
Eles operam por meio de Reduções ao invés de Derivações como no caso das Gramáticas e
Analisadores LL(K) \cite{ahoCompilerDragonBook}.

Uma Derivação acontece quando uma regra de produção como ``$S \Rightarrow a a $'' de uma gramática expande e
tem~=se como resultado ``$a a$'' a partir do símbolo de origem ``$S$''.
Já uma Redução acontece quanto a dada regra de produção como ``$S \Rightarrow a a $'' de uma gramática reduz e
tem~=se como resultado ``$S$'' a partir do símbolo de origem ``$a a$''.

Tanto Derivações quanto Reduções podem ser descritas em termos que quantos passos são necessários para que se possa sair de um ponto até outro:
\begin{enumerate}%[nosep,nolistsep]
    \item Quanto um derivação é denotada como ``$S \Rightarrow a a $'',
    isso significa que somente um passo é necessário para sair do símbolo inicial ``$S$'' e
    chegar no símbolo final ``$a a$'';
    \item Quanto um derivação é denotada como ``$S \xRightarrow{*} a a $'',
    isso significa que são necessários,
    desde zero (nenhum) até infinitos passos para sair do símbolo inicial ``$S$'' e
    chegar no símbolo final ``$a a$'';
    \item Quanto um derivação é denotada como ``$S \xRightarrow{+} a a $'',
    isso significa que são necessários,
    desde um passo até infinitos passos para sair do símbolo inicial ``$S$'' e
    chegar no símbolo final ``$a a$''.
\end{enumerate}

Para reduções,
estas mesmas condições se aplicam,
mas em ordem reversa,
i.e., $\Leftarrow$, $\xLeftarrow{*}$ e $\xLeftarrow{+}$,
ao invés de $\Rightarrow$,
$\xRightarrow{*}$ e
$\xRightarrow{+}$ \cite{ahoCompilerDragonBook}.
Enquanto gramáticas são geradores de palavras que partem do símbolo inicial da gramática até gerarem uma palavra da linguagem,
Analisadores Ascendentes como LR(K) são reconhecedores de palavras.

Diferente de gramáticas,
Analisadores Ascendentes partem de uma palavra da linguagem até chegarem no símbolo inicial da gramática,
consumindo toda a palavra de entrada e
chegando em um Estado de Aceitação.
Já Analisadores Descendentes como LL(K),
partem do símbolo inicial da gramática até consumirem toda palavra de entrada,
também chegando um em Estado de Aceitação.

Ambos os Analisadores Ascendentes ou
Descendentes,
terminam no final do processo,
gerando toda a Árvore de Derivação.
Entretanto,
caso no final do processo,
não chegue~=se em um Estado de Aceitação \cite{ahoCompilerDragonBook},
tem~=se somente a construção de uma Árvore de Derivação partial.
No caso dos Analisadores Ascendentes,
será uma floresta de árvores,
porque somente no final da análise,
com a chegada ao símbolo inicial da gramática,
completa~=se custura de todas a árvores que foram parcialmente construídas durante o processo de análise (\textit{Bottom~=Up}).
Já no caso dos Analisadores Descendentes,
não existe uma floresta de árvores.
Como parte~=se diretamente do símbolo inicial da gramática,
a Árvore de Derivação desde o começo é construído como sendo uma única árvore (\textit{Top~=Down}).
Em caso de erros na construção da Árvore Sintática,
ela terminará somente com algumas nós folha faltando.


\subsection{Analisadores LR(K)}

Como pode ser observado na \typeref{LinguagensDeterministicas},
existem Gramáticas SLR(K) que não são Gramáticas LL(K) porque para uma gramática ser LL(K),
ela precisa respeitar 3 propriedades:
\begin{inparaenum}[1)]
    \item Não possuir Recursão a Esquerda;
    \item Estar fatorada e;
    \item $\forall\; A\, \in\, V_n\; |\; A\,
            \xRightarrow{*}\, \varepsilon\,
            \land\, First(A)\, \cap\, Follow(A) = \varnothing$.
\end{inparaenum}%
\cite{ahoCompilerDragonBook}.

Entretanto,
Gramáticas LR(K), LALR(K) e
SLR(K) não precisam de nenhuma dessas restrições.
No caso da Recursão a Esquerda,
o algoritmo de criação da Tabela de Análise Sintática da Gramática LR(K),
LALR(K) ou SLR(K),
não possui o problema de entrar em um loop infinito assim como acontecem com as Gramáticas LL(K),
portanto aceitando~=se Gramáticas com Recursão a Esquerda \cite{ahoCompilerDragonBook}.

Analisadores LR(K) requerem grandes quantidades de memória,
proporcional ao tamanho da gramáticas de entrada para operar \cite{complexityOfLRKTesting}.
Por isso,
\citeonline{lalrDeRemer1982},
criaram os Analisadores LALR(K)\footnote{
Do inglês, \textit{Look~=Ahead} LA(K) LR(0),
onde LR(0) é um Analisador LR(K) com $K=0$.
}
e SLR(K)\footnote{
Do inglês, \textit{Simple LR(K) parser}.
}
com o objeto de viabilizar a implementação de Analisadores Ascendentes Determinísticos.

Gramáticas de Linguagens Determinísticas são chamadas de LR,
porque todas as Linguagens Determinísticas são reconhecidas por Analisadores LR(K),
uma vez que \citeonline{knuthLrParser1965},
provou que todas as Gramáticas Determinísticas são aceitas por um Analisador LR(K).
Assim,
além da hierarquia de Chomsky,
também classifica~=se as gramáticas de acordo com o tipo de analisador que reconhece as linguagens representadas por elas.
Como mostrado na \typeref{LinguagensDeterministicas},
nem todas as Gramáticas Livre de Contexto são de gramáticas Determinísticas e
uma gramática é Determinística somente se ela pode ser reconhecida por um Analisador LR(K).

Portanto,
uma maneira fácil de decidir se uma dada gramática é determinística ou
não,
é tentar construir a sua Tabela de Análise para um Analisador LR(K).
Caso consiga~=se construir com sucesso (sem conflitos) a Tabela de Análise Sintática \cite{ahoCompilerDragonBook},
a gramática é LR(K),
caso contrário a gramática não é determinística.
A mesma técnica pode ser aplicada no caso de analisadores menos poderosos como LALR(K),
entretanto,
uma vez que não se consiga construir a Tabela de Análise Sintática,
não se pode ter certeza se dada gramática é ou
não determinística.


\subsection{Análise Semântica}
\label{analiseSemantica}

Usualmente\footnote{
Como será apresentado mais a frente nesta seção:
\begin{inparaenum}[1)]
\item O processo de Análise Semântica pode acontecer ao mesmo tempo que a Análise Sintática;
\item Por fim,
a Árvore Sintática também pode nem ser gerada em um estrutura de dados,
ocorrendo diretamente Análise Semântica seguido da Geração de Código.
\end{inparaenum}%
},
somente depois que a Árvore Sintática é construída,
realiza~=se o processo de Análise Semântica \cite{ahoCompilerDragonBook},
i.e.,
a verificação da corretude do programa escrito em relação os aspectos não~=estruturais.
Por exemplo,
é sintaticamente correto escrever a declaração de uma mesma variável duas vezes ou
mais. Entretanto,
para algumas linguagens é semanticamente errado redeclarar uma variável duas vezes ou
mais.

O Analisador Sintático representado por uma Gramática Livre de Contexto não tem poder suficiente para realizar verificações de significado,
devido as limitações desse tipo de gramática,
que restringem~=se a estrutura do programa e
não a seu significado (semântica).

Nem todas as linguagens podem ser analisadas completamente em diferentes etapas,
como Análise Léxica, Sintática e Semântica. Muitas vezes,
estas três etapas acontecem em paralelo como realizado na implementação do compilador da Linguagem C \cite{jourdan2017,whyCcannotBeParsedWithALR1Parser}.
A Gramática da Linguagem C não é Livre de Contexto Determinística devido as ambiguidades\footnote{
Conhecido também como Não~=Determinismo,
veja o \fullref{exemploDeAmbiguidadeLinguistica}.
}
existentes como a expressão ``\textit{x * y ;}''.
Tal sentença pode ser ou
a declaração de um ponteiro chamado \textit{y} do tipo \textit{x},
ou a multiplicação de dois números armazenados nas variáveis \textit{x} e
\textit{y},
portanto ela não pode ser aceita por um Analisador LR(K) tradicional,
pois sua gramática é ambígua.

\begin{quadro}[!htb]
\caption{Exemplo de Ambiguidade Linguística}
\label{exemploDeAmbiguidadeLinguistica}
\begin{bluebox}
    SOCORRO!

    UM TIGRE DE BENGALA ESTÁ ME ATACANDO!

    \begin{enumerate}%[nosep,nolistsep]
        \item Um tigre que está utilizando uma bengala para se locomover está atrás de você;
        \item Um tigre que veio da grande área metropolitana de Bengala na Ásia está atrás de você;
        \item Um torcedor do Criciúma (tigre) que usa sua bengala,
        depois que seu time perdeu de 7 à 1 está atrás de você.
    \end{enumerate}
\end{bluebox}
\end{quadro}

O compilador da linguagem C consegue fazer a ``Análise Determinística\footnote{
Como o Compilador da Linguagem C é escrito programaticamente,
ele é equivalente a uma Máquina de Turing e
portanto possui em pior caso,
tempo infinito de execução,
reveja a \fullref{FigureHierarquiaDeChomsky}.
}'' da linguagem tratando a ambiguidade relativa ao uso do símbolo asterisco ou
estrela ``*'' como operador de multiplicação ou
declaração de variável do tipo ponteiro.
Assim consegue saber se a expressão ``\textit{x * y ;}'' trata~=se de de uma mera multiplicação ou
a declaração de uma variável,
com a realização ``simultânea'' da Análise Léxica,
Sintática e
Semântica.

Uma vez que um novo \textit{token} é reconhecido,
ele é alimentado para o Analisador Sintático,
que também o alimenta o Analisador Semântico,
que alimenta a Tabela de Símbolos.
Assim,
o Analisador Sintático é capaz de consultar a Tabela de Símbolos \cite{ahoCompilerDragonBook} e
descobrir se dado \textit{token} ou
tratar~=se de um tipo ou
uma variável numérica.

\advisor{Requer~=se}{Entretanto,
requer~=se} cuidado sobre como as alterações do Analisador são feitas,
pois pode~=se pensar que todas as gramáticas de todas as linguagens de programação são ``Livres de Contexto'' e
Determinísticas,
o que não é verdade,
veja a próxima \fullref{alteracoesNosAnalisadoresSintaticos}.
Uma vez que a gramática não é mais Livre de Contexto ou
Determinística,
pode~=se mover Aspectos Sensíveis ao Contexto para o Analisador Semântico,
assim,
deixando a gramática somente com aspectos determinísticos.


\subsection{Alterações nos Analisadores Sintáticos}
\label{alteracoesNosAnalisadoresSintaticos}

Dependendo de como o Analisador Sintático de Gramáticas Livre de Contexto é alterado,
o conjunto de gramáticas aceitas por tal analisador pode deixar de serem Livres de Contexto.
As gramáticas somente continuarão Livre de Contexto caso estas alterações sejam somente mover checagens da etapa de Análise Sintática para a etapa de Análise Semântica sem realizar alterações no Analisador Sintático.

Quanto se adiciona suporte a Aspectos Sensíveis ao Contexto \cite{contextSensitiveParsing} a Gramáticas Livre de Contexto por meio de alterações do Analisador Sintático,
como feito no Analisador da Linguagem C,
o analisador da gramática deixa de ser Livre de Contexto,
suportando assim,
algumas Gramáticas Sensíveis ao Contexto e\slash{}ou também algumas Gramáticas Não~=Determinísticas.

Note que,
a pesar disso não impede~=se que a gramática da Linguagem C,
como mostrado na seção anterior,
seja analisada com eficiência.
Mas isso deixa a brechas para que ela possa não ser analisada com eficiência.
A diferença para um analisador onde a gramática é inteiramente Livre de Contexto,
é que elas tem performance \textit{garantida} pela sua Classe de Complexidade (Veja a \fullref{classesDeComplexidade}).

Sintaxe e
Semântica de Linguagens são completamente ortogonais.
Gramáticas de Linguagens Irrestritas\footnote{
Não a linguagem na qual elas representam,
mas a própria gramática em si \cite{finiteAutomataTuringComplete}.
}
podem ser Turing Completas\footnote{
A Turing Completude acontece quando uma dada linguagem pode simular o funcionamento completo de uma Máquina de Turing.
}
devido a sua equivalência com Máquinas de Turing e
são capazes de realizar qualquer operação computacional.
Mas,
isso não pode ser confundido com as \textit{Strings} ou
Programas gerados por essas gramáticas \cite{areThereDomainSpecificLanguages}.

Tais programas podem ou
não ser Turing Completos.
Do lado oposto,
até Linguagens Regulares podem gerar programas que são Turing Completos,
mesmo que seu dispositivo reconhecedor equivalente,
os Autômatos Finitos,
não tenham Turing Completude\footnote{
Caso isso esteja confuso,
reveja a \typeref{FigureHierarquiaDeChomsky} e
note que de todas as Linguagens,
quem tem Turing Completude são as Linguagens Irrestritas,
enquanto Autômatos Finitos são um subconjunto das Máquinas de Turing \cite{finiteAutomataTuringComplete}.
}
\cite{turingCompleteRegularLanguages,finiteAutomataTuringComplete}.

No \fullref{software_implementation},
será mostrado a implementação de uma Gramática ``Livre de Contexto'' em um Analisador LALR(1),
onde Aspectos Sensíveis ao Contexto serão analisados pelo Analisador Semântico,
tal como feito na implementação do Compilador da Linguagem C apresentado.
Mas com a diferença de que utiliza~=se um Analisador LALR(1) genérico,
ao contrário de um analisador feito exclusivamente para a linguagem alvo.

Este Analisador LALR(1),
possui suporte a pequenos ``\textit{\englishword{hacks}}'' ou
otimizações que permitem adicionar alguns aspectos Sensíveis ao Contexto ao Analisador LALR(1).
Assim,
as gramáticas aceitas por esse analisador incluem somente algumas Gramáticas Não~=Determinísticas,
não incluindo todas as Gramáticas Livre de Contexto Ambíguas ou
Sensíveis ao Contexto devido a limitações das alterações do algoritmo de Análise LALR(1) \cite{larkContextualLexer}.


\section{\advisor{Compiladores e }{}Classes de Complexidade}
\label{classesDeComplexidade}

Como um todo,
o conjunto de Linguagens Regulares pode ser considerado com complexidade linear\footnote{
Complexidade linear é um caso particular de complexidade polinomial onde o grau do Polinômio é 1,
i.e.,
$\Theta(n)$.
Aprenda mais sobre complexidade linear com \citeonline{cormenIntroductionToAlgorithms,computationalComplexityAuroraBarak}.
}
em tempo computacional para determinar de dada palavra pertence ou
não a linguagem,
porque toda Gramática Regular Não~=Determinística pode ser convertida em uma Gramática Regular Determinística \cite{sipserBook}.

Infelizmente isso não é verdade para Gramáticas Livres de Contexto,
porque Gramáticas Livre de Contexto Determinísticas e
Não~=Determinísticas não são equivalentes e
uma não pode ser convertida em outra.
Gramáticas Não~=Determinísticas possuem complexidade exponential,
quando analisadas por um Analisador com Backtracking.
Em contra~=partida,
Gramáticas Livre de Contexto Não~=Determinísticas também podem ser analisadas em tempo polinomial,
por exemplo,
com complexidade de tempo $\Theta(n^3)$ ao utilizar o algoritmo de parsing CYK (\citeonline{larkContextualLexer} e
\fullref{sectionHierarquiaDeChomsky}).


\advisor{}{%
\subsection{Computadores Quânticos}

    Com a exceção de alguns problemas específicos \cite{theGoodAndBadQuantumComputing},
    a execução probabilística de Computadores Quânticos \cite{nonlinearQuantumComputers},
    baseados nas leis da Física Quântica \cite{dicke1963QuantumPhysicsIntroduction},
    podem cortar\footnote{
    Devido as probabilidades envolvidas,
    somente um ou
    alguns dos ramos de computação serão seguidos durante a execução do Algoritmo Quântico,
    pelo Computador Quântico.
    }
    caminho ``pulando'' ramos de Computação Não~=Determinísticos (da computação Clássica) com a superposição quântica.
    Assim,
    conseguindo resolver alguns problemas que são exponenciais,
    em tempo polinomial ao tamanho da entrada,
    utilizando algoritmos específicos para computadores quânticos \cite{quantumComputerSurvey,quantumSimulatorChagas}.

    Esta é a gama de problemas nos quais Computadores Quânticos são úteis \cite{quantumComputingForNonPhysicists},
    não sendo assim,
    substitutos completos da Computação Tradicional (ou Clássica) \cite{efficientQuantumComputation},
    somente otimizadores na resolução de alguns problemas que podem ser otimizados devido as propriedades específicas\slash{}probabilísticas das leis Física Quântica \cite{churchTuringQuantumComputer}.

    Pode~=se confundir Computadores Quânticos como equivalentes a Analisadores Não~=Determinísticos devido as nomenclaturas utilizadas.
    Enquanto analisadores são Não~=Determinísticos devido à ambiguidades nas gramáticas de entrada,
    Computadores Quânticos são Não Determinísticos devido à serem baseado em modelos Probabilísticos,
    i.e.,
    Computadores Quânticos não são equivalentes a Analisadores Não~=Determinísticos devido a sua execução ser probabilística \cite{polynomialQuantumComputers,probabilisticQuantumComputation,quantumSimulatorChagas}.

    Diferente dos Computadores Tradicionais,
    Computadores Quânticos são construídos com base nas leis da Física Quântica,
    que são radicalmente diferentes das Leis da Física Tradicional ou
    Clássica, i.e.,
    as Leis de Newton.
    As Leis da Física Clássica regem os elementos muitos grandes na escala galáxias,
    planetas, células e
    virus \cite{halliday2013fundamentals}.
    Já as Leis da Física Quântica regem as elementos muito pequenos na escala de átomos,
    elétrons, prótons, fótons e
    \textit{quarks} \cite{dicke1963QuantumPhysicsIntroduction}.
}


\subsection{Complexidade Teórica $versus$ Real}

Na \typeref{ParserNonDeterministic},
encontra~=se uma Árvore de Computação de um Analisador Não~=Determinístico.
Diz~=se que que o tempo de execução de um Analisador Não~=Determinístico é Não~=Determinístico Polinomial ($NP$\footnote{
Do inglês, \textit{Non~=Deterministic Polynomial Time},
comumente conhecida pela pergunta,
$P \stackrel{?}{=} NP$, i.e.,
a classe de problemas com complexidade de tempo Determinístico Polinomial,
está estritamente contida na classe de problemas $NP$ (Não~=Determinísticos Polinomiais) \cite{computationalComplexityAuroraBarak}?
})
ao tamanho da entrada,
porque um Analisador Não~=Determinístico executa simultaneamente todos os ramos de Computação Não~=Determinísticos \cite{hopcroftBook}.

Como mostrado na \typeref{ParserNonDeterministic},
após a cada um dos passo de computação 1,
2, 3 e 4,
todos os 15 ramos de computação foram concluídos.
Cada um desses passos é corresponde a um item a ser analisado na entrada do programa.
E esta computação,
acontece em tempo Não~=Determinístico Polinomial,
com expoente de $n$ igual a $1$,
i.e.,
$\Theta(n^1)$.
\begin{figure}[!htb]
\caption{Árvore de Computação com 4 Passos\protect\footnotemark{} de um Problema da Classe $NP$}
\label{ParserNonDeterministic}
\centering
\includegraphics[width=1.0\textwidth]{ParserNonDeterministic.png}
\fonte{Própria}
\end{figure}
\footnotetext{Não~=Determinísticos.}

O que torna a computação Não~=Determinística\footnote{
E pertencente a classe dos problemas Não~=Determinístico Polinomial.
} é o fato de cada um dos itens 1,
2, 3 e 4 da entrada,
permitirem simultaneamente a escolha de mais de um caminho na escolha do próximo estado do analisador,
i.e.,
mais de um Ramo de Computação,
devido a ambiguidades da gramática de entrada \cite{detectingAmbiguityInGrammars,antlrBookTerrentParr}.

Nesse contexto,
$P$ representa o conjunto de problemas resolvidos tempo Determinístico Polinomial (por Máquinas de Turing Determinísticas),
enquanto $NP$ o conjunto de Problemas resolvido em tempo Não~=Determinístico Polinomial (por Máquinas de Turing Não~=Determinísticas).
Assim,
um problema Não~=Determinístico Polinomial somente pode ser resolvido por uma Máquinas de Turing Determinística em tempo exponencial.
Veja as \typeref{ParserNonDeterministic,ParserDeterministic} e
as compare.

O tempo de execução será linear ao tamanho da entrada caso o Analisador Não~=Determinístico seja de uma Linguagem Regular e
implementado através de um Autômato Finito.
O tempo de execução será polinomial ao tamanho da entrada caso o Analisador Não~=Determinístico seja de uma Linguagem Livre de Contexto Ambígua (Gramática Não~=Determinística) e
implementado através de algum algoritmo com tempo polinomial como CYK (\fullref{sectionHierarquiaDeChomsky}).

Como já explicado nas observações da \typeref{FigureHierarquiaDeChomsky},
existem duas classes distintas de complexidade para Gramáticas Livre de Contexto Não~=Determinísticas.
Quando faz~=se uma Análise de uma Gramáticas Livre de Contexto Não~=Determinística,
tem~=se como resultado várias possíveis Árvores de Derivação\footnote{
Como a gramática é Não~=Determinística,
existem muitas possíveis Árvores de Derivação,
(devido à ambiguidades da gramática).
}.


\subsection{Mecanismos Reconhecedores}
\label{mecanismosReconhecedores}

Uma vez que o conjunto de Linguagens Determinísticas LR(K) (com tempo linear) está contida no conjunto das Linguagens Livres de Contexto,
não considera~=se tempos Análise Lineares ou
Polinomiais de execução para Linguagens Sensíveis ao Contexto ou
Irrestritas,
porque tudo o que é eficiente é Livre de Contexto e
Determinístico e
Gramáticas Sensíveis ao Contexto terão em pior caso,
complexidade exponential \cite{growingContextSensitiveLanguages}.

Máquinas de Turing Não~=Determinísticas que resolvem os problemas da Classe $NP$ em tempo Não~=Determinístico Polinomial não existem fisicamente,
portanto sua complexidade de tempo reduzida não pode ser alcançada e
seu tempo de execução é Determinístico Exponential,
pois para simular o funcionamento de uma Máquina de Turing Não~=Determinística,
utiliza~=se uma Máquina de Turing Determinística\footnote{
Máquinas de Turing Determinísticas seriam os equivalentes aos computadores de propósito geral.
}
\cite{sipserBook,turingMachinesRoyer}.

Máquinas de Turing Determinísticas e
Não~=Determinísticas são equivalentes,
pois sempre é possível simular o funcionamento de uma Máquina de Turing Não~=Determinística,
utilizando uma Máquina de Turing Determinística \cite{hopcroftBook}.

Na \typeref{ParserDeterministic},
encontra~=se a mesma Árvore de Computação apresentada na \typeref{ParserNonDeterministic},
mas com a diferença de que desta vez utiliza~=se uma Máquina de Turing Determinística ao contrário de uma Máquina de Turing Não~=Determinística.
Com isso,
ao invés de um tempo polinomial ao tamanho da entrada,
tem~=se um tempo exponential ao tamanho da entrada.
\begin{figure}[!htb]
\caption{Árvore de Computação com 15 Passos (Determinísticos)}
\label{ParserDeterministic}
\centering
\includegraphics[width=1.0\textwidth]{ParserDeterministicDepth.png}
\fonte{Própria}
\end{figure}

Para que uma Máquina de Turing Determinística possa processar uma Gramática Não~=Determinística,
é necessário execute cada um dos ramos de computação.
Já Máquinas de Turing Não~=Determinísticas\footnote{
Máquinas de Turing da classe $NP$,
somente existem teoricamente,
com a exceção de algums trabalhos como \citeonline{efficientNonDeterministicParsers},
que tenta utilizar computação paralela para representar o Não~=Determinismo.
}
executam simultaneamente todos os ramos de computação Não~=determinísticos,
conseguindo assim, desempenho linear ou
polinomial ao tamanho da entrada compondo os problemas da classe $NP$ (com tempo Não~=Determinístico Polinomial) \cite{hopcroftBook}.


\subsection{Busca em Largura e Profundidade}
\label{buscaEmLarguraEProfundidade}

Quando uma Máquina de Turing Determinística é utilizado para simular o funcionamento de uma Máquina de Turing Não~=Determinística,
ela precisa decidir como escolher executar os Ramos de Computação Não~=Determinísticos \cite{sipserBook}.
Duas principais abordagens distintas e
conhecidas\footnote{
Além dessas duas abordagens,
existem muitas outras técnicas que podem ser cridas como misturas dessas duas estratégias extremas,
como heurísticas e inteligências artificias.
}
são a Busca em Largura\footnote{
Do inglês, \textit{Breadth-First Search (BFS)}.
}
e Busca em Profundidade\footnote{
Do inglês, \textit{Depth-First Search (DFS)}.
}.
Os algoritmos funcionamento desses tipos de busca são detalhadas em \citeonline{cormenIntroductionToAlgorithms}.

Cada uma delas apresenta suas vantagens e
desvantagens.
Uma vantagem da Busca em Profundidade é possibilidade de ``sorte'',
caso o primeiro ramo não~=determinístico que escolhe~=se seja uma solução para o problema,
i.e.,
leve o analisador a um estado de aceitação,
mas ao mesmo tempo de pode~=se ter ``sorte'',
pode~=se ter o ``azar'' de que o primeiro ramo não~=determinístico seja um ramo infinito de computações que nunca levarão o analisador à um estado de aceitação.

A \typeref{ParserDeterministic},
mostrou um exemplo de uso do algoritmo de Busca em Profundidade.
Já na \typeref{ParserDeterministicBreadth},
encontra~=se a variação de execução de um Analisador Determinístico que utilizou o algoritmo de Busca em Largura.
\begin{figure}[!htb]
\caption{Árvore de Computação com 15 Passos\protect\footnotemark{} utilizando Busca em Largura}
\label{ParserDeterministicBreadth}
\centering
\includegraphics[width=1.0\textwidth]{ParserDeterministicBreadth.png}
\fonte{Própria}
\end{figure}
\footnotetext{Não~=Determinísticos.}

Tanto o algoritmo de Busca em Largura quanto Busca em Profundidade,
não precisam exatamente seguir resolvendo o problema pela esquerda ou
direita.
O que importa é a sua característica de avançar até o fim de algum dado ramo de computação,
ou seguir executando todos os ramos que fazem parte de um mesmo nível de computação \cite{cormenIntroductionToAlgorithms,efficientBreadthFirstSearch}.

